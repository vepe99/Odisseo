{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "107c77d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 13:15:01.674525: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746011701.696635 3739922 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746011701.704143 3739922 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746011701.720544 3739922 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746011701.720567 3739922 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746011701.720568 3739922 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746011701.720569 3739922 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "/export/home/vgiusepp/miniconda3/envs/sbi_ds/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "import haiku as hk\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from tensorflow_probability.substrates import jax as tfp\n",
    "tfb = tfp.bijectors\n",
    "tfd = tfp.distributions\n",
    "\n",
    "\n",
    "from normflow_models import (AffineCoupling,\n",
    "                             AffineSigmoidCoupling,\n",
    "                             ConditionalRealNVP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02a5bb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class to Train the compressor, in our case we are going to train \n",
    "#the compressor with the vmim, so we will also need a Normalizing Flow \n",
    "#  which is going to be trained with the compressor\n",
    "\n",
    "class TrainModel:\n",
    "    def __init__(\n",
    "        self,\n",
    "        compressor,\n",
    "        nf,\n",
    "        optimizer,\n",
    "        loss_name,\n",
    "        dim=None,\n",
    "        info_compressor=None,\n",
    "    ):\n",
    "        self.compressor = compressor\n",
    "        self.nf = nf\n",
    "        self.optimizer = optimizer\n",
    "        self.dim = dim  # summary statistic dimension\n",
    "\n",
    "        if loss_name == \"train_compressor_mse\":\n",
    "            self.loss = self.loss_mse\n",
    "        elif loss_name == \"train_compressor_vmim\":\n",
    "            self.loss = self.loss_vmim\n",
    "        elif loss_name == \"train_compressor_gnll\":\n",
    "            self.loss = self.loss_gnll\n",
    "            if self.dim is None:\n",
    "                raise ValueError(\"dim should be specified when using gnll compressor\")\n",
    "        elif loss_name == \"loss_for_sbi\":\n",
    "            if info_compressor is None:\n",
    "                raise ValueError(\"sbi loss needs compressor informations\")\n",
    "            else:\n",
    "                self.info_compressor = info_compressor\n",
    "                self.loss = self.loss_nll\n",
    "\n",
    "    def loss_mse(self, params, theta, x, state_resnet):\n",
    "        \"\"\"Compute the Mean Squared Error loss\"\"\"\n",
    "        y, opt_state_resnet = self.compressor.apply(params, state_resnet, None, x)\n",
    "\n",
    "        loss = jnp.mean(jnp.sum((y - theta) ** 2, axis=1))\n",
    "\n",
    "        return loss, opt_state_resnet\n",
    "\n",
    "    def loss_mae(self, params, theta, x, state_resnet):\n",
    "        \"\"\"Compute the Mean Absolute Error loss\"\"\"\n",
    "        y, opt_state_resnet = self.compressor.apply(params, state_resnet, None, x)\n",
    "\n",
    "        loss = jnp.mean(jnp.sum(jnp.absolute(y - theta), axis=1))\n",
    "\n",
    "        return loss, opt_state_resnet\n",
    "\n",
    "    def loss_vmim(self, params, theta, x, state_resnet):\n",
    "        \"\"\"Compute the Variational Mutual Information Maximization loss\"\"\"\n",
    "        y, opt_state_resnet = self.compressor.apply(params, state_resnet, None, x)\n",
    "        log_prob = self.nf.apply(params, theta, y)\n",
    "\n",
    "        return -jnp.mean(log_prob), opt_state_resnet\n",
    "\n",
    "    def loss_gnll(self, params, theta, x, state_resnet):\n",
    "        \"\"\"Compute the Gaussian Negative Log Likelihood loss\"\"\"\n",
    "        y, opt_state_resnet = self.compressor.apply(params, state_resnet, None, x)\n",
    "        y_mean = y[..., : self.dim]\n",
    "        y_var = y[..., self.dim :]\n",
    "        y_var = tfb.FillScaleTriL(diag_bijector=tfb.Softplus(low=1e-3)).forward(y_var)\n",
    "\n",
    "        @jax.jit\n",
    "        @jax.vmap\n",
    "        def _get_log_prob(y_mean, y_var, theta):\n",
    "            likelihood = tfd.MultivariateNormalTriL(y_mean, y_var)\n",
    "            return likelihood.log_prob(theta)\n",
    "\n",
    "        loss = -jnp.mean(_get_log_prob(y_mean, y_var, theta))\n",
    "\n",
    "        return loss, opt_state_resnet\n",
    "\n",
    "    def loss_nll(self, params, theta, x, _):\n",
    "        \"\"\"Compute the Negative Log Likelihood loss.\n",
    "        This loss is for inference so it requires to have a trained compressor.\n",
    "        \"\"\"\n",
    "        y, _ = self.compressor.apply(\n",
    "            self.info_compressor[0], self.info_compressor[1], None, x\n",
    "        )\n",
    "        log_prob = self.nf.apply(params, theta, y)\n",
    "\n",
    "        return -jnp.mean(log_prob), _\n",
    "\n",
    "    @partial(jax.jit, static_argnums=(0,))\n",
    "    def update(self, model_params, opt_state, theta, x, state_resnet=None):\n",
    "        (loss, opt_state_resnet), grads = jax.value_and_grad(self.loss, has_aux=True)(\n",
    "            model_params, theta, x, state_resnet\n",
    "        )\n",
    "\n",
    "        updates, new_opt_state = self.optimizer.update(grads, opt_state)\n",
    "\n",
    "        new_params = optax.apply_updates(model_params, updates)\n",
    "\n",
    "        return loss, new_params, new_opt_state, opt_state_resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36dabbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "#mimic the argument parser used in the sbi_bm_lens\n",
    "\n",
    "class args_namedtuple(NamedTuple):\n",
    "\n",
    "    total_steps = 50,\n",
    "\n",
    "    loss = \"train_compressor_vmim\",\n",
    "\n",
    "\n",
    "args = args_namedtuple()\n",
    "dim = 10\n",
    "N_particles = 10_000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17114efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### create compressor \n",
    "\n",
    "#nf \n",
    "bijector_layers_compressor = [128] * 2\n",
    "\n",
    "bijector_compressor = partial(\n",
    "    AffineCoupling, layers=bijector_layers_compressor, activation=jax.nn.silu\n",
    ")\n",
    "\n",
    "NF_compressor = partial(ConditionalRealNVP, n_layers=4, bijector_fn=bijector_compressor)\n",
    "\n",
    "\n",
    "class Flow_nd_Compressor(hk.Module):\n",
    "    def __call__(self, y):\n",
    "        nvp = NF_compressor(dim)(y)\n",
    "        return nvp\n",
    "\n",
    "\n",
    "nf = hk.without_apply_rng(\n",
    "    hk.transform(lambda theta, y: Flow_nd_Compressor()(y).log_prob(theta).squeeze())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03cdfdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.loss == \"train_compressor_gnll\":\n",
    "    compress_dim = int(dim + ((dim**2) - dim) / 2 + dim)\n",
    "else:\n",
    "    compress_dim = dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "045c7918",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepSetsEncoder(hk.Module):\n",
    "    def __init__(self, output_dim, hidden_dim: int = 128, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def __call__(self, x):  # x: [N_particles, 6]\n",
    "        # Ï† network: shared across all particles\n",
    "        mlp_phi = hk.nets.MLP([self.hidden_dim, self.hidden_dim, self.output_dim])\n",
    "        x_phi = mlp_phi(x)  # shape: [N_particles, output_dim]\n",
    "\n",
    "        # Pooling over the set dimension (e.g., mean, sum)\n",
    "        summary = jnp.mean(x_phi, axis=0)  # shape: [output_dim]\n",
    "\n",
    "        return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3481ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressor = hk.transform_with_state(\n",
    "    lambda y: DeepSetsEncoder(compress_dim)(y)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0ebbc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRAIN\n",
    "# init compressor\n",
    "parameters_SetNet, opt_state_SetNet = compressor.init(\n",
    "    jax.random.PRNGKey(0), y=jnp.ones([1, N_particles, 6])\n",
    ")\n",
    "\n",
    "# init nf\n",
    "params_nf = nf.init(\n",
    "    jax.random.PRNGKey(0), theta=0.5 * jnp.ones([1, 5]), y=0.5 * jnp.ones([1, dim])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe9793d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/51 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0 theta (1, 5) x (1, 10000, 6) score (1, 5)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot concatenate arrays with shapes that differ in dimensions other than the one being concatenated: concatenating along dimension 1 for shapes (1, 5), (10000, 10).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 73\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbatch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m theta \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtheta.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m x \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m score \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m jnp.isnan(score).any():\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     b_loss, parameters_compressor, opt_state_c, opt_state_SetNet = \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters_compressor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43mopt_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mopt_state_c\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_resnet\u001b[49m\u001b[43m=\u001b[49m\u001b[43mopt_state_SetNet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m     store_loss.append(b_loss)\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m jnp.isnan(b_loss):\n",
      "    \u001b[31m[... skipping hidden 30 frame]\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 88\u001b[39m, in \u001b[36mTrainModel.update\u001b[39m\u001b[34m(self, model_params, opt_state, theta, x, state_resnet)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;129m@partial\u001b[39m(jax.jit, static_argnums=(\u001b[32m0\u001b[39m,))\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_params, opt_state, theta, x, state_resnet=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     (loss, opt_state_resnet), grads = \u001b[43mjax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_resnet\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m     updates, new_opt_state = \u001b[38;5;28mself\u001b[39m.optimizer.update(grads, opt_state)\n\u001b[32m     94\u001b[39m     new_params = optax.apply_updates(model_params, updates)\n",
      "    \u001b[31m[... skipping hidden 16 frame]\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 54\u001b[39m, in \u001b[36mTrainModel.loss_vmim\u001b[39m\u001b[34m(self, params, theta, x, state_resnet)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compute the Variational Mutual Information Maximization loss\"\"\"\u001b[39;00m\n\u001b[32m     53\u001b[39m y, opt_state_resnet = \u001b[38;5;28mself\u001b[39m.compressor.apply(params, state_resnet, \u001b[38;5;28;01mNone\u001b[39;00m, x)\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m log_prob = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m -jnp.mean(log_prob), opt_state_resnet\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sbi_ds/lib/python3.12/site-packages/haiku/_src/multi_transform.py:315\u001b[39m, in \u001b[36mwithout_apply_rng.<locals>.apply_fn\u001b[39m\u001b[34m(params, *args, **kwargs)\u001b[39m\n\u001b[32m    313\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply_fn\u001b[39m(params, *args, **kwargs):\n\u001b[32m    314\u001b[39m   check_rng_kwarg(kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m315\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sbi_ds/lib/python3.12/site-packages/haiku/_src/transform.py:183\u001b[39m, in \u001b[36mwithout_state.<locals>.apply_fn\u001b[39m\u001b[34m(params, *args, **kwargs)\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[32m    177\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    178\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mHaiku transform adds three arguments (params, state, rng) to apply. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    179\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mIf the functions you are transforming use the same names you must \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    180\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mpass them positionally (e.g. `f.apply(.., my_state)` and not by \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    181\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mname (e.g. `f.apply(.., state=my_state)`)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m out, state = \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m state:\n\u001b[32m    185\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m base.NonEmptyStateError(\n\u001b[32m    186\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mIf your transformed function uses `hk.\u001b[39m\u001b[33m{\u001b[39m\u001b[33mget,set}_state` then use \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    187\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33m`hk.transform_with_state`.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sbi_ds/lib/python3.12/site-packages/haiku/_src/transform.py:456\u001b[39m, in \u001b[36mtransform_with_state.<locals>.apply_fn\u001b[39m\u001b[34m(params, state, rng, *args, **kwargs)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m base.new_context(params=params, state=state, rng=rng) \u001b[38;5;28;01mas\u001b[39;00m ctx:\n\u001b[32m    455\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     out = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m   \u001b[38;5;28;01mexcept\u001b[39;00m jax.errors.UnexpectedTracerError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    458\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m jax.errors.UnexpectedTracerError(unexpected_tracer_hint) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(theta, y)\u001b[39m\n\u001b[32m     15\u001b[39m         nvp = NF_compressor(dim)(y)\n\u001b[32m     16\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m nvp\n\u001b[32m     19\u001b[39m nf = hk.without_apply_rng(\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     hk.transform(\u001b[38;5;28;01mlambda\u001b[39;00m theta, y: \u001b[43mFlow_nd_Compressor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m)\u001b[49m.squeeze())\n\u001b[32m     21\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sbi_ds/lib/python3.12/site-packages/tensorflow_probability/substrates/jax/distributions/distribution.py:1287\u001b[39m, in \u001b[36mDistribution.log_prob\u001b[39m\u001b[34m(self, value, name, **kwargs)\u001b[39m\n\u001b[32m   1275\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlog_prob\u001b[39m(\u001b[38;5;28mself\u001b[39m, value, name=\u001b[33m'\u001b[39m\u001b[33mlog_prob\u001b[39m\u001b[33m'\u001b[39m, **kwargs):\n\u001b[32m   1276\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Log probability density/mass function.\u001b[39;00m\n\u001b[32m   1277\u001b[39m \n\u001b[32m   1278\u001b[39m \u001b[33;03m  Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1285\u001b[39m \u001b[33;03m      values of type `self.dtype`.\u001b[39;00m\n\u001b[32m   1286\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1287\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_log_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sbi_ds/lib/python3.12/site-packages/tensorflow_probability/substrates/jax/distributions/distribution.py:1269\u001b[39m, in \u001b[36mDistribution._call_log_prob\u001b[39m\u001b[34m(self, value, name, **kwargs)\u001b[39m\n\u001b[32m   1267\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._name_and_control_scope(name, value, kwargs):\n\u001b[32m   1268\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m_log_prob\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1269\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_log_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1270\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m_prob\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m   1271\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tf.math.log(\u001b[38;5;28mself\u001b[39m._prob(value, **kwargs))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sbi_ds/lib/python3.12/site-packages/tensorflow_probability/substrates/jax/distributions/transformed_distribution.py:364\u001b[39m, in \u001b[36m_TransformedDistribution._log_prob\u001b[39m\u001b[34m(self, y, **kwargs)\u001b[39m\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_log_prob\u001b[39m(\u001b[38;5;28mself\u001b[39m, y, **kwargs):\n\u001b[32m    363\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bijector._is_injective:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m     log_prob, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexperimental_local_measure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackward_compat\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    366\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m log_prob\n\u001b[32m    368\u001b[39m   \u001b[38;5;66;03m# TODO(b/197680518): Support base measure handling for non-injective\u001b[39;00m\n\u001b[32m    369\u001b[39m   \u001b[38;5;66;03m# bijectors.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sbi_ds/lib/python3.12/site-packages/tensorflow_probability/substrates/jax/distributions/transformed_distribution.py:611\u001b[39m, in \u001b[36m_TransformedDistribution.experimental_local_measure\u001b[39m\u001b[34m(self, y, backward_compat, **kwargs)\u001b[39m\n\u001b[32m    607\u001b[39m distribution_kwargs, bijector_kwargs = \u001b[38;5;28mself\u001b[39m._kwargs_split_fn(kwargs)\n\u001b[32m    609\u001b[39m \u001b[38;5;66;03m# For caching to work, it is imperative that the bijector is the first to\u001b[39;00m\n\u001b[32m    610\u001b[39m \u001b[38;5;66;03m# modify the input.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m611\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbijector\u001b[49m\u001b[43m.\u001b[49m\u001b[43minverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mbijector_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    612\u001b[39m event_ndims = \u001b[38;5;28mself\u001b[39m.bijector.inverse_event_ndims(\n\u001b[32m    613\u001b[39m     tf.nest.map_structure(ps.rank_from_shape, \u001b[38;5;28mself\u001b[39m._event_shape_tensor(),\n\u001b[32m    614\u001b[39m                           \u001b[38;5;28mself\u001b[39m.event_shape), **bijector_kwargs)\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bijector._is_injective:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sbi_ds/lib/python3.12/site-packages/tensorflow_probability/substrates/jax/bijectors/bijector.py:1390\u001b[39m, in \u001b[36mBijector.inverse\u001b[39m\u001b[34m(self, y, name, **kwargs)\u001b[39m\n\u001b[32m   1372\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minverse\u001b[39m(\u001b[38;5;28mself\u001b[39m, y, name=\u001b[33m'\u001b[39m\u001b[33minverse\u001b[39m\u001b[33m'\u001b[39m, **kwargs):\n\u001b[32m   1373\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Returns the inverse `Bijector` evaluation, i.e., X = g^{-1}(Y).\u001b[39;00m\n\u001b[32m   1374\u001b[39m \n\u001b[32m   1375\u001b[39m \u001b[33;03m  Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1388\u001b[39m \u001b[33;03m    NotImplementedError: if `_inverse` is not implemented.\u001b[39;00m\n\u001b[32m   1389\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1390\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_inverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sbi_ds/lib/python3.12/site-packages/tensorflow_probability/substrates/jax/bijectors/bijector.py:1370\u001b[39m, in \u001b[36mBijector._call_inverse\u001b[39m\u001b[34m(self, y, name, **kwargs)\u001b[39m\n\u001b[32m   1368\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_injective:  \u001b[38;5;66;03m# No caching for non-injective\u001b[39;00m\n\u001b[32m   1369\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._inverse(y, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1370\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cache\u001b[49m\u001b[43m.\u001b[49m\u001b[43minverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sbi_ds/lib/python3.12/site-packages/tensorflow_probability/substrates/jax/internal/cache_util.py:347\u001b[39m, in \u001b[36mBijectorCache.inverse\u001b[39m\u001b[34m(self, y, **kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minverse\u001b[39m(\u001b[38;5;28mself\u001b[39m, y, **kwargs):\n\u001b[32m    337\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Invokes the 'inverse' transformation, or looks up previous results.\u001b[39;00m\n\u001b[32m    338\u001b[39m \n\u001b[32m    339\u001b[39m \u001b[33;03m  Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    345\u001b[39m \u001b[33;03m    The output of the bijector's `_inverse` method, or a cached result.\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_lookup\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inverse_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sbi_ds/lib/python3.12/site-packages/tensorflow_probability/substrates/jax/internal/cache_util.py:493\u001b[39m, in \u001b[36mBijectorCache._lookup\u001b[39m\u001b[34m(self, input, forward_name, inverse_name, **kwargs)\u001b[39m\n\u001b[32m    487\u001b[39m   output = output_ref()\n\u001b[32m    488\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    489\u001b[39m   \u001b[38;5;66;03m# Get the output structure, and declare a\u001b[39;00m\n\u001b[32m    490\u001b[39m   \u001b[38;5;66;03m# weakref to clear it from the cache once it gets GCed\u001b[39;00m\n\u001b[32m    491\u001b[39m   output = nest.map_structure(\n\u001b[32m    492\u001b[39m       _containerize,\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m       \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_invoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    494\u001b[39m   output_ref = WeakStructRef(\n\u001b[32m    495\u001b[39m       output,\n\u001b[32m    496\u001b[39m       subkey=(\u001b[38;5;28mself\u001b[39m.bijector, \u001b[38;5;28mself\u001b[39m.bijector_class, inverse_name, kwargs),\n\u001b[32m    497\u001b[39m       callback=\u001b[38;5;28mself\u001b[39m.storage.maybe_del)\n\u001b[32m    498\u001b[39m   \u001b[38;5;66;03m# Set the input->output mapping.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sbi_ds/lib/python3.12/site-packages/tensorflow_probability/substrates/jax/internal/cache_util.py:532\u001b[39m, in \u001b[36mBijectorCache._invoke\u001b[39m\u001b[34m(self, input, fn_name, kwargs, attributes)\u001b[39m\n\u001b[32m    530\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_invoke\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, fn_name, kwargs, attributes):  \u001b[38;5;66;03m# pylint: disable=unused-argument\u001b[39;00m\n\u001b[32m    531\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Invokes the wrapped function. Override to customize behavior.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m532\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbijector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sbi_ds/lib/python3.12/site-packages/tensorflow_probability/substrates/jax/bijectors/composition.py:614\u001b[39m, in \u001b[36mComposition._inverse\u001b[39m\u001b[34m(self, y, **kwargs)\u001b[39m\n\u001b[32m    610\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_injective:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m    611\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m    612\u001b[39m       \u001b[33m'\u001b[39m\u001b[33mInvert is not implemented for compositions of \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    613\u001b[39m       \u001b[33m'\u001b[39m\u001b[33mnon-injective bijectors.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m614\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_walk_inverse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    615\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m.\u001b[49m\u001b[43minverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    616\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sbi_ds/lib/python3.12/site-packages/tensorflow_probability/substrates/jax/bijectors/composition.py:352\u001b[39m, in \u001b[36mComposition._call_walk_inverse\u001b[39m\u001b[34m(self, step_fn, *args, **kwargs)\u001b[39m\n\u001b[32m    348\u001b[39m args = \u001b[38;5;28mtuple\u001b[39m(nest_util.coerce_structure(\u001b[38;5;28mself\u001b[39m.inverse_min_event_ndims, y)\n\u001b[32m    349\u001b[39m              \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m args)\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) == \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m352\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_walk_inverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[38;5;66;03m# Convert a tuple of structures to a structure of tuples. This\u001b[39;00m\n\u001b[32m    355\u001b[39m \u001b[38;5;66;03m# allows `_walk` methods to route aligned structures of inputs/outputs\u001b[39;00m\n\u001b[32m    356\u001b[39m \u001b[38;5;66;03m# independently, obviates the need for conditional tuple unpacking.\u001b[39;00m\n\u001b[32m    357\u001b[39m packed_args = pack_structs_like(\u001b[38;5;28mself\u001b[39m.inverse_min_event_ndims, *args)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sbi_ds/lib/python3.12/site-packages/tensorflow_probability/substrates/jax/bijectors/chain.py:150\u001b[39m, in \u001b[36m_Chain._walk_inverse\u001b[39m\u001b[34m(self, step_fn, y, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Applies `transform_fn` to `y` sequentially over nested bijectors.\"\"\"\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m bij \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bijectors:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   y = \u001b[43mstep_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbij\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbij\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sbi_ds/lib/python3.12/site-packages/tensorflow_probability/substrates/jax/bijectors/composition.py:615\u001b[39m, in \u001b[36mComposition._inverse.<locals>.<lambda>\u001b[39m\u001b[34m(b, y, **kwargs)\u001b[39m\n\u001b[32m    610\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_injective:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m    611\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m    612\u001b[39m       \u001b[33m'\u001b[39m\u001b[33mInvert is not implemented for compositions of \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    613\u001b[39m       \u001b[33m'\u001b[39m\u001b[33mnon-injective bijectors.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    614\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_walk_inverse(\n\u001b[32m--> \u001b[39m\u001b[32m615\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m b, y, **kwargs: \u001b[43mb\u001b[49m\u001b[43m.\u001b[49m\u001b[43minverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    616\u001b[39m     y, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sbi_ds/lib/python3.12/site-packages/tensorflow_probability/substrates/jax/bijectors/bijector.py:1390\u001b[39m, in \u001b[36mBijector.inverse\u001b[39m\u001b[34m(self, y, name, **kwargs)\u001b[39m\n\u001b[32m   1372\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minverse\u001b[39m(\u001b[38;5;28mself\u001b[39m, y, name=\u001b[33m'\u001b[39m\u001b[33minverse\u001b[39m\u001b[33m'\u001b[39m, **kwargs):\n\u001b[32m   1373\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Returns the inverse `Bijector` evaluation, i.e., X = g^{-1}(Y).\u001b[39;00m\n\u001b[32m   1374\u001b[39m \n\u001b[32m   1375\u001b[39m \u001b[33;03m  Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1388\u001b[39m \u001b[33;03m    NotImplementedError: if `_inverse` is not implemented.\u001b[39;00m\n\u001b[32m   1389\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1390\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_inverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sbi_ds/lib/python3.12/site-packages/tensorflow_probability/substrates/jax/bijectors/bijector.py:1370\u001b[39m, in \u001b[36mBijector._call_inverse\u001b[39m\u001b[34m(self, y, name, **kwargs)\u001b[39m\n\u001b[32m   1368\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_injective:  \u001b[38;5;66;03m# No caching for non-injective\u001b[39;00m\n\u001b[32m   1369\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._inverse(y, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1370\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cache\u001b[49m\u001b[43m.\u001b[49m\u001b[43minverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sbi_ds/lib/python3.12/site-packages/tensorflow_probability/substrates/jax/internal/cache_util.py:347\u001b[39m, in \u001b[36mBijectorCache.inverse\u001b[39m\u001b[34m(self, y, **kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minverse\u001b[39m(\u001b[38;5;28mself\u001b[39m, y, **kwargs):\n\u001b[32m    337\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Invokes the 'inverse' transformation, or looks up previous results.\u001b[39;00m\n\u001b[32m    338\u001b[39m \n\u001b[32m    339\u001b[39m \u001b[33;03m  Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    345\u001b[39m \u001b[33;03m    The output of the bijector's `_inverse` method, or a cached result.\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_lookup\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inverse_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sbi_ds/lib/python3.12/site-packages/tensorflow_probability/substrates/jax/internal/cache_util.py:493\u001b[39m, in \u001b[36mBijectorCache._lookup\u001b[39m\u001b[34m(self, input, forward_name, inverse_name, **kwargs)\u001b[39m\n\u001b[32m    487\u001b[39m   output = output_ref()\n\u001b[32m    488\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    489\u001b[39m   \u001b[38;5;66;03m# Get the output structure, and declare a\u001b[39;00m\n\u001b[32m    490\u001b[39m   \u001b[38;5;66;03m# weakref to clear it from the cache once it gets GCed\u001b[39;00m\n\u001b[32m    491\u001b[39m   output = nest.map_structure(\n\u001b[32m    492\u001b[39m       _containerize,\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m       \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_invoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    494\u001b[39m   output_ref = WeakStructRef(\n\u001b[32m    495\u001b[39m       output,\n\u001b[32m    496\u001b[39m       subkey=(\u001b[38;5;28mself\u001b[39m.bijector, \u001b[38;5;28mself\u001b[39m.bijector_class, inverse_name, kwargs),\n\u001b[32m    497\u001b[39m       callback=\u001b[38;5;28mself\u001b[39m.storage.maybe_del)\n\u001b[32m    498\u001b[39m   \u001b[38;5;66;03m# Set the input->output mapping.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sbi_ds/lib/python3.12/site-packages/tensorflow_probability/substrates/jax/internal/cache_util.py:532\u001b[39m, in \u001b[36mBijectorCache._invoke\u001b[39m\u001b[34m(self, input, fn_name, kwargs, attributes)\u001b[39m\n\u001b[32m    530\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_invoke\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, fn_name, kwargs, attributes):  \u001b[38;5;66;03m# pylint: disable=unused-argument\u001b[39;00m\n\u001b[32m    531\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Invokes the wrapped function. Override to customize behavior.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m532\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbijector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sbi_ds/lib/python3.12/site-packages/tensorflow_probability/substrates/jax/bijectors/composition.py:614\u001b[39m, in \u001b[36mComposition._inverse\u001b[39m\u001b[34m(self, y, **kwargs)\u001b[39m\n\u001b[32m    610\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_injective:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m    611\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m    612\u001b[39m       \u001b[33m'\u001b[39m\u001b[33mInvert is not implemented for compositions of \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    613\u001b[39m       \u001b[33m'\u001b[39m\u001b[33mnon-injective bijectors.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m614\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_walk_inverse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    615\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m.\u001b[49m\u001b[43minverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    616\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sbi_ds/lib/python3.12/site-packages/tensorflow_probability/substrates/jax/bijectors/composition.py:352\u001b[39m, in \u001b[36mComposition._call_walk_inverse\u001b[39m\u001b[34m(self, step_fn, *args, **kwargs)\u001b[39m\n\u001b[32m    348\u001b[39m args = \u001b[38;5;28mtuple\u001b[39m(nest_util.coerce_structure(\u001b[38;5;28mself\u001b[39m.inverse_min_event_ndims, y)\n\u001b[32m    349\u001b[39m              \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m args)\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) == \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m352\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_walk_inverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[38;5;66;03m# Convert a tuple of structures to a structure of tuples. This\u001b[39;00m\n\u001b[32m    355\u001b[39m \u001b[38;5;66;03m# allows `_walk` methods to route aligned structures of inputs/outputs\u001b[39;00m\n\u001b[32m    356\u001b[39m \u001b[38;5;66;03m# independently, obviates the need for conditional tuple unpacking.\u001b[39;00m\n\u001b[32m    357\u001b[39m packed_args = pack_structs_like(\u001b[38;5;28mself\u001b[39m.inverse_min_event_ndims, *args)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sbi_ds/lib/python3.12/site-packages/tensorflow_probability/substrates/jax/bijectors/chain.py:150\u001b[39m, in \u001b[36m_Chain._walk_inverse\u001b[39m\u001b[34m(self, step_fn, y, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Applies `transform_fn` to `y` sequentially over nested bijectors.\"\"\"\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m bij \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bijectors:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   y = \u001b[43mstep_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbij\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbij\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sbi_ds/lib/python3.12/site-packages/tensorflow_probability/substrates/jax/bijectors/composition.py:615\u001b[39m, in \u001b[36mComposition._inverse.<locals>.<lambda>\u001b[39m\u001b[34m(b, y, **kwargs)\u001b[39m\n\u001b[32m    610\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_injective:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m    611\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m    612\u001b[39m       \u001b[33m'\u001b[39m\u001b[33mInvert is not implemented for compositions of \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    613\u001b[39m       \u001b[33m'\u001b[39m\u001b[33mnon-injective bijectors.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    614\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_walk_inverse(\n\u001b[32m--> \u001b[39m\u001b[32m615\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m b, y, **kwargs: \u001b[43mb\u001b[49m\u001b[43m.\u001b[49m\u001b[43minverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    616\u001b[39m     y, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sbi_ds/lib/python3.12/site-packages/tensorflow_probability/substrates/jax/bijectors/bijector.py:1390\u001b[39m, in \u001b[36mBijector.inverse\u001b[39m\u001b[34m(self, y, name, **kwargs)\u001b[39m\n\u001b[32m   1372\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minverse\u001b[39m(\u001b[38;5;28mself\u001b[39m, y, name=\u001b[33m'\u001b[39m\u001b[33minverse\u001b[39m\u001b[33m'\u001b[39m, **kwargs):\n\u001b[32m   1373\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Returns the inverse `Bijector` evaluation, i.e., X = g^{-1}(Y).\u001b[39;00m\n\u001b[32m   1374\u001b[39m \n\u001b[32m   1375\u001b[39m \u001b[33;03m  Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1388\u001b[39m \u001b[33;03m    NotImplementedError: if `_inverse` is not implemented.\u001b[39;00m\n\u001b[32m   1389\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1390\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_inverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sbi_ds/lib/python3.12/site-packages/tensorflow_probability/substrates/jax/bijectors/bijector.py:1370\u001b[39m, in \u001b[36mBijector._call_inverse\u001b[39m\u001b[34m(self, y, name, **kwargs)\u001b[39m\n\u001b[32m   1368\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_injective:  \u001b[38;5;66;03m# No caching for non-injective\u001b[39;00m\n\u001b[32m   1369\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._inverse(y, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1370\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cache\u001b[49m\u001b[43m.\u001b[49m\u001b[43minverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sbi_ds/lib/python3.12/site-packages/tensorflow_probability/substrates/jax/internal/cache_util.py:347\u001b[39m, in \u001b[36mBijectorCache.inverse\u001b[39m\u001b[34m(self, y, **kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minverse\u001b[39m(\u001b[38;5;28mself\u001b[39m, y, **kwargs):\n\u001b[32m    337\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Invokes the 'inverse' transformation, or looks up previous results.\u001b[39;00m\n\u001b[32m    338\u001b[39m \n\u001b[32m    339\u001b[39m \u001b[33;03m  Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    345\u001b[39m \u001b[33;03m    The output of the bijector's `_inverse` method, or a cached result.\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_lookup\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inverse_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sbi_ds/lib/python3.12/site-packages/tensorflow_probability/substrates/jax/internal/cache_util.py:493\u001b[39m, in \u001b[36mBijectorCache._lookup\u001b[39m\u001b[34m(self, input, forward_name, inverse_name, **kwargs)\u001b[39m\n\u001b[32m    487\u001b[39m   output = output_ref()\n\u001b[32m    488\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    489\u001b[39m   \u001b[38;5;66;03m# Get the output structure, and declare a\u001b[39;00m\n\u001b[32m    490\u001b[39m   \u001b[38;5;66;03m# weakref to clear it from the cache once it gets GCed\u001b[39;00m\n\u001b[32m    491\u001b[39m   output = nest.map_structure(\n\u001b[32m    492\u001b[39m       _containerize,\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m       \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_invoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    494\u001b[39m   output_ref = WeakStructRef(\n\u001b[32m    495\u001b[39m       output,\n\u001b[32m    496\u001b[39m       subkey=(\u001b[38;5;28mself\u001b[39m.bijector, \u001b[38;5;28mself\u001b[39m.bijector_class, inverse_name, kwargs),\n\u001b[32m    497\u001b[39m       callback=\u001b[38;5;28mself\u001b[39m.storage.maybe_del)\n\u001b[32m    498\u001b[39m   \u001b[38;5;66;03m# Set the input->output mapping.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sbi_ds/lib/python3.12/site-packages/tensorflow_probability/substrates/jax/internal/cache_util.py:532\u001b[39m, in \u001b[36mBijectorCache._invoke\u001b[39m\u001b[34m(self, input, fn_name, kwargs, attributes)\u001b[39m\n\u001b[32m    530\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_invoke\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, fn_name, kwargs, attributes):  \u001b[38;5;66;03m# pylint: disable=unused-argument\u001b[39;00m\n\u001b[32m    531\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Invokes the wrapped function. Override to customize behavior.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m532\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbijector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sbi_ds/lib/python3.12/site-packages/tensorflow_probability/substrates/jax/bijectors/real_nvp.py:298\u001b[39m, in \u001b[36mRealNVP._inverse\u001b[39m\u001b[34m(self, y, **condition_kwargs)\u001b[39m\n\u001b[32m    295\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._reverse_mask:\n\u001b[32m    296\u001b[39m   y0, y1 = y1, y0\n\u001b[32m--> \u001b[39m\u001b[32m298\u001b[39m x1 = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bijector_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bijector_input_units\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m                       \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcondition_kwargs\u001b[49m\u001b[43m)\u001b[49m.inverse(y1)\n\u001b[32m    301\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._reverse_mask:\n\u001b[32m    302\u001b[39m   x1, y0 = y0, x1\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sbi_ds/lib/python3.12/site-packages/haiku/_src/module.py:464\u001b[39m, in \u001b[36mwrap_method.<locals>.wrapped\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    461\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m method_name != \u001b[33m\"\u001b[39m\u001b[33m__call__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    462\u001b[39m     f = jax.named_call(f, name=method_name)\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m out = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[38;5;66;03m# Module names are set in the constructor. If `f` is the constructor then\u001b[39;00m\n\u001b[32m    467\u001b[39m \u001b[38;5;66;03m# its name will only be set **after** `f` has run. For methods other\u001b[39;00m\n\u001b[32m    468\u001b[39m \u001b[38;5;66;03m# than `__init__` we need the name before running in order to wrap their\u001b[39;00m\n\u001b[32m    469\u001b[39m \u001b[38;5;66;03m# execution with `named_call`.\u001b[39;00m\n\u001b[32m    470\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m module_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sbi_ds/lib/python3.12/contextlib.py:81\u001b[39m, in \u001b[36mContextDecorator.__call__.<locals>.inner\u001b[39m\u001b[34m(*args, **kwds)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(*args, **kwds):\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._recreate_cm():\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sbi_ds/lib/python3.12/site-packages/haiku/_src/module.py:305\u001b[39m, in \u001b[36mrun_interceptors\u001b[39m\u001b[34m(bound_method, method_name, self, orig_class, *args, **kwargs)\u001b[39m\n\u001b[32m    303\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Runs any method interceptors or the original method.\"\"\"\u001b[39;00m\n\u001b[32m    304\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m interceptor_stack:\n\u001b[32m--> \u001b[39m\u001b[32m305\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    307\u001b[39m ctx = MethodContext(module=\u001b[38;5;28mself\u001b[39m,\n\u001b[32m    308\u001b[39m                     method_name=method_name,\n\u001b[32m    309\u001b[39m                     orig_method=bound_method,\n\u001b[32m    310\u001b[39m                     orig_class=orig_class)\n\u001b[32m    311\u001b[39m interceptor_stack_copy = interceptor_stack.clone()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Odisseo/notebooks/dev/sbi/sbi_ds/ds_nbody/normflow_models.py:149\u001b[39m, in \u001b[36mAffineCoupling.__call__\u001b[39m\u001b[34m(self, x, output_units, **condition_kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, output_units, **condition_kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     net = \u001b[43mjnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43my\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, layer_size \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.layers):\n\u001b[32m    151\u001b[39m         net = \u001b[38;5;28mself\u001b[39m.activation(hk.Linear(layer_size, name=\u001b[33m\"\u001b[39m\u001b[33mlayer\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m\"\u001b[39m % i)(net))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sbi_ds/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py:4648\u001b[39m, in \u001b[36mconcatenate\u001b[39m\u001b[34m(arrays, axis, dtype)\u001b[39m\n\u001b[32m   4646\u001b[39m k = \u001b[32m16\u001b[39m\n\u001b[32m   4647\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(arrays_out) > \u001b[32m1\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m4648\u001b[39m   arrays_out = [\u001b[43mlax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays_out\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[43m+\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4649\u001b[39m                 \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(arrays_out), k)]\n\u001b[32m   4650\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m arrays_out[\u001b[32m0\u001b[39m]\n",
      "    \u001b[31m[... skipping hidden 17 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sbi_ds/lib/python3.12/site-packages/jax/_src/lax/lax.py:6655\u001b[39m, in \u001b[36m_concatenate_shape_rule\u001b[39m\u001b[34m(*operands, **kwargs)\u001b[39m\n\u001b[32m   6651\u001b[39m   msg = (\u001b[33m\"\u001b[39m\u001b[33mCannot concatenate arrays with shapes that differ in dimensions \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   6652\u001b[39m          \u001b[33m\"\u001b[39m\u001b[33mother than the one being concatenated: concatenating along \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   6653\u001b[39m          \u001b[33m\"\u001b[39m\u001b[33mdimension \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m for shapes \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6654\u001b[39m   shapes = [operand.shape \u001b[38;5;28;01mfor\u001b[39;00m operand \u001b[38;5;129;01min\u001b[39;00m operands]\n\u001b[32m-> \u001b[39m\u001b[32m6655\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg.format(dimension, \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m, shapes))))\n\u001b[32m   6657\u001b[39m concat_size = \u001b[38;5;28msum\u001b[39m(o.shape[dimension] \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m operands)\n\u001b[32m   6658\u001b[39m ex_shape = operands[\u001b[32m0\u001b[39m].shape\n",
      "\u001b[31mTypeError\u001b[39m: Cannot concatenate arrays with shapes that differ in dimensions other than the one being concatenated: concatenating along dimension 1 for shapes (1, 5), (10000, 10)."
     ]
    }
   ],
   "source": [
    "if args.loss[0] == \"train_compressor_vmim\":\n",
    "    parameters_compressor = hk.data_structures.merge(parameters_SetNet, params_nf)\n",
    "elif args.loss[0] in [\n",
    "    \"train_compressor_mse\",\n",
    "    \"train_compressor_mae\",\n",
    "    \"train_compressor_gnll\",\n",
    "]:\n",
    "    parameters_compressor = parameters_SetNet\n",
    "\n",
    "\n",
    "# define optimizer\n",
    "total_steps = args.total_steps[0]\n",
    "\n",
    "if args.loss == \"train_compressor_gnll\":\n",
    "    start_lr = 0.0001\n",
    "\n",
    "else:\n",
    "    start_lr = 0.001\n",
    "\n",
    "lr_scheduler = optax.piecewise_constant_schedule(\n",
    "    init_value=start_lr,\n",
    "    boundaries_and_scales={\n",
    "        int(total_steps * 0.1): 0.7,\n",
    "        int(total_steps * 0.2): 0.7,\n",
    "        int(total_steps * 0.3): 0.7,\n",
    "        int(total_steps * 0.4): 0.7,\n",
    "        int(total_steps * 0.5): 0.7,\n",
    "        int(total_steps * 0.6): 0.7,\n",
    "        int(total_steps * 0.7): 0.7,\n",
    "        int(total_steps * 0.8): 0.7,\n",
    "        int(total_steps * 0.9): 0.7,\n",
    "    },\n",
    ")\n",
    "\n",
    "optimizer_c = optax.adam(learning_rate=lr_scheduler)\n",
    "opt_state_c = optimizer_c.init(parameters_compressor)\n",
    "\n",
    "model_compressor = TrainModel(\n",
    "    compressor=compressor,\n",
    "    nf=nf,\n",
    "    optimizer=optimizer_c,\n",
    "    loss_name=args.loss[0],\n",
    ")\n",
    "\n",
    "\n",
    "update = jax.jit(model_compressor.update)\n",
    "\n",
    "\n",
    "#load data\n",
    "data_path = './data/data_NFW/'\n",
    "pattern = re.compile(r\"chunk_(\\d+)\\.npz\")  # capture any number of digits\n",
    "files = sorted(\n",
    "    f for f in Path(data_path).glob(\"chunk_*.npz\")\n",
    "    if (m := pattern.fullmatch(f.name)) and int(m.group(1)) < 1000\n",
    ")\n",
    "theta_list, x_list, score_list = [], [], []\n",
    "for f in files:\n",
    "    data = np.load(f)\n",
    "    theta_list.append(data[\"theta\"].reshape(1, -1))\n",
    "    x_list.append(data[\"x\"].reshape(1, 10_000, 6))\n",
    "    score_list.append(data[\"score\"].reshape(1, -1))  \n",
    "dataset_theta = jnp.stack(theta_list,)\n",
    "dataset_y = jnp.stack(x_list, )\n",
    "dataset_score = jnp.stack(score_list,)\n",
    "\n",
    "store_loss = []\n",
    "for batch in tqdm(range(total_steps + 1)):\n",
    "    theta = dataset_theta[batch]\n",
    "    x = dataset_y[batch]\n",
    "    score = dataset_score[batch]\n",
    "    print(f\"batch {batch} theta {theta.shape} x {x.shape} score {score.shape}\")\n",
    "    if not jnp.isnan(score).any():\n",
    "        b_loss, parameters_compressor, opt_state_c, opt_state_SetNet = update(\n",
    "            model_params=parameters_compressor,\n",
    "            opt_state=opt_state_c,\n",
    "            theta=theta,\n",
    "            x=x,\n",
    "            state_resnet=opt_state_SetNet,\n",
    "        )\n",
    "        store_loss.append(b_loss)\n",
    "\n",
    "        if jnp.isnan(b_loss):\n",
    "            print(\"NaN Loss\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "98ef204a",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_list = []\n",
    "x_list = []\n",
    "score_list = []\n",
    "\n",
    "for f in files:\n",
    "    data = np.load(f)\n",
    "    theta_list.append(data[\"theta\"])\n",
    "    x_list.append(data[\"x\"])\n",
    "    score_list.append(data[\"score\"]) \n",
    "    \n",
    "dataset_theta = jnp.array(theta_list,).reshape(-1, 5)\n",
    "dataset_y = jnp.array(x_list, ).reshape(-1, 10_000, 6)\n",
    "dataset_score = jnp.stack(score_list,).reshape(-1, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626f3064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta shape (1001, 1, 5)\n",
      "x shape (1001, 1, 10000, 6)\n",
      "score shape (1001, 1, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"theta shape\", dataset_theta.shape)\n",
    "print(\"x shape\", dataset_y.sh\n",
    "      ape)\n",
    "print(\"score shape\", dataset_score.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f5c60c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbi_ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
