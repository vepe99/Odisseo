{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "107c77d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 17:22:06.210450: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746804126.372278  134878 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746804126.421442  134878 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746804126.772971  134878 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746804126.773002  134878 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746804126.773004  134878 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746804126.773005  134878 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "# from autocvd import autocvd\n",
    "# autocvd(num_gpus = 1)\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import jit\n",
    "import optax\n",
    "import haiku as hk\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from tensorflow_probability.substrates import jax as tfp\n",
    "tfb = tfp.bijectors\n",
    "tfd = tfp.distributions\n",
    "\n",
    "\n",
    "from normflow_models import (AffineCoupling,\n",
    "                             AffineSigmoidCoupling,\n",
    "                             ConditionalRealNVP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02a5bb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class to Train the compressor, in our case we are going to train \n",
    "#the compressor with the vmim, so we will also need a Normalizing Flow \n",
    "#  which is going to be trained with the compressor\n",
    "\n",
    "class TrainModel:\n",
    "    def __init__(\n",
    "        self,\n",
    "        compressor,\n",
    "        nf,\n",
    "        optimizer,\n",
    "        loss_name,\n",
    "        dim=None,\n",
    "        info_compressor=None,\n",
    "    ):\n",
    "        self.compressor = compressor\n",
    "        self.nf = nf\n",
    "        self.optimizer = optimizer\n",
    "        self.dim = dim  # summary statistic dimension\n",
    "\n",
    "        if loss_name == \"train_compressor_mse\":\n",
    "            self.loss = self.loss_mse\n",
    "        elif loss_name == \"train_compressor_vmim\":\n",
    "            self.loss = self.loss_vmim\n",
    "        elif loss_name == \"train_compressor_gnll\":\n",
    "            self.loss = self.loss_gnll\n",
    "            if self.dim is None:\n",
    "                raise ValueError(\"dim should be specified when using gnll compressor\")\n",
    "        elif loss_name == \"loss_for_sbi\":\n",
    "            if info_compressor is None:\n",
    "                raise ValueError(\"sbi loss needs compressor informations\")\n",
    "            else:\n",
    "                self.info_compressor = info_compressor\n",
    "                self.loss = self.loss_nll\n",
    "\n",
    "    def loss_mse(self, params, theta, x, state_resnet):\n",
    "        \"\"\"Compute the Mean Squared Error loss\"\"\"\n",
    "        y, opt_state_resnet = self.compressor.apply(params, state_resnet, None, x)\n",
    "\n",
    "        loss = jnp.mean(jnp.sum((y - theta) ** 2, axis=1))\n",
    "\n",
    "        return loss, opt_state_resnet\n",
    "\n",
    "    def loss_mae(self, params, theta, x, state_resnet):\n",
    "        \"\"\"Compute the Mean Absolute Error loss\"\"\"\n",
    "        y, opt_state_resnet = self.compressor.apply(params, state_resnet, None, x)\n",
    "\n",
    "        loss = jnp.mean(jnp.sum(jnp.absolute(y - theta), axis=1))\n",
    "\n",
    "        return loss, opt_state_resnet\n",
    "\n",
    "    def loss_vmim(self, params, theta, x, state_resnet):\n",
    "        \"\"\"Compute the Variational Mutual Information Maximization loss\"\"\"\n",
    "        y, opt_state_resnet = self.compressor.apply(params, state_resnet, None, x)\n",
    "        log_prob = self.nf.apply(params, theta, y)\n",
    "\n",
    "        return -jnp.mean(log_prob), opt_state_resnet\n",
    "\n",
    "    def loss_gnll(self, params, theta, x, state_resnet):\n",
    "        \"\"\"Compute the Gaussian Negative Log Likelihood loss\"\"\"\n",
    "        y, opt_state_resnet = self.compressor.apply(params, state_resnet, None, x)\n",
    "        y_mean = y[..., : self.dim]\n",
    "        y_var = y[..., self.dim :]\n",
    "        y_var = tfb.FillScaleTriL(diag_bijector=tfb.Softplus(low=1e-3)).forward(y_var)\n",
    "\n",
    "        @jax.jit\n",
    "        @jax.vmap\n",
    "        def _get_log_prob(y_mean, y_var, theta):\n",
    "            likelihood = tfd.MultivariateNormalTriL(y_mean, y_var)\n",
    "            return likelihood.log_prob(theta)\n",
    "\n",
    "        loss = -jnp.mean(_get_log_prob(y_mean, y_var, theta))\n",
    "\n",
    "        return loss, opt_state_resnet\n",
    "\n",
    "    def loss_nll(self, params, theta, x, _):\n",
    "        \"\"\"Compute the Negative Log Likelihood loss.\n",
    "        This loss is for inference so it requires to have a trained compressor.\n",
    "        \"\"\"\n",
    "        y, _ = self.compressor.apply(\n",
    "            self.info_compressor[0], self.info_compressor[1], None, x\n",
    "        )\n",
    "        log_prob = self.nf.apply(params, theta, y)\n",
    "\n",
    "        return -jnp.mean(log_prob), _\n",
    "\n",
    "    @partial(jax.jit, static_argnums=(0,))\n",
    "    def update(self, model_params, opt_state, theta, x, state_resnet=None):\n",
    "        (loss, opt_state_resnet), grads = jax.value_and_grad(self.loss, has_aux=True)(\n",
    "            model_params, theta, x, state_resnet\n",
    "        )\n",
    "\n",
    "        updates, new_opt_state = self.optimizer.update(grads, opt_state)\n",
    "\n",
    "        new_params = optax.apply_updates(model_params, updates)\n",
    "\n",
    "        return loss, new_params, new_opt_state, opt_state_resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36dabbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "#mimic the argument parser used in the sbi_bm_lens\n",
    "\n",
    "class args_namedtuple(NamedTuple):\n",
    "\n",
    "    total_steps = 4500,\n",
    "\n",
    "    loss = \"train_compressor_vmim\",\n",
    "    # loss = \"train_compressor_mse\",\n",
    "\n",
    "\n",
    "args = args_namedtuple()\n",
    "dim = 64\n",
    "N_particles = 10_000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17114efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### create compressor \n",
    "\n",
    "#nf \n",
    "bijector_layers_compressor = [128] * 2\n",
    "\n",
    "bijector_compressor = partial(\n",
    "    AffineCoupling, layers=bijector_layers_compressor, activation=jax.nn.silu\n",
    ")\n",
    "\n",
    "NF_compressor = partial(ConditionalRealNVP, n_layers=4, bijector_fn=bijector_compressor)\n",
    "\n",
    "\n",
    "class Flow_nd_Compressor(hk.Module):\n",
    "    def __call__(self, y):\n",
    "        nvp = NF_compressor(dim)(y)\n",
    "        return nvp\n",
    "\n",
    "\n",
    "nf = hk.without_apply_rng(\n",
    "    hk.transform(lambda theta, y: Flow_nd_Compressor()(theta).log_prob(y).squeeze())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03cdfdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.loss == \"train_compressor_gnll\":\n",
    "    compress_dim = int(dim + ((dim**2) - dim) / 2 + dim)\n",
    "else:\n",
    "    compress_dim = dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "045c7918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DeepSetsEncoder(hk.Module):\n",
    "#     def __init__(self, output_dim, hidden_dim: int = 128, name=None):\n",
    "#         super().__init__(name=name)\n",
    "#         self.hidden_dim = hidden_dim\n",
    "#         self.output_dim = output_dim\n",
    "\n",
    "#     def __call__(self, x):  # x: [N_particles, 6]\n",
    "#         # Ï† network: shared across all particles\n",
    "#         mlp_phi = hk.nets.MLP([self.hidden_dim, self.hidden_dim, self.output_dim])\n",
    "#         x_phi = mlp_phi(x)  # shape: [N_particles, output_dim]\n",
    "\n",
    "#         # Pooling over the set dimension (e.g., mean, sum)\n",
    "#         summary = jnp.mean(x_phi, axis=0)  # shape: [output_dim]\n",
    "\n",
    "#         return summary\n",
    "\n",
    "\n",
    "class DeepSetsEncoder(hk.Module):\n",
    "    def __init__(self, output_dim, hidden_dim: int = 128, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def __call__(self, x):  # x: [N_particles, 6] or [B, N_particles, 6]\n",
    "        mlp_phi = hk.nets.MLP([self.hidden_dim, self.hidden_dim, self.hidden_dim, self.output_dim])\n",
    "\n",
    "        if x.ndim == 2:\n",
    "            # Unbatched case: [N_particles, 6]\n",
    "            x_phi = mlp_phi(x)  # [N_particles, output_dim]\n",
    "            summary = jnp.mean(x_phi, axis=0)  # [output_dim]\n",
    "        elif x.ndim == 3:\n",
    "            # Batched case: [B, N_particles, 6]\n",
    "            # Flatten for MLP: [B * N_particles, 6]\n",
    "            B, N, D = x.shape\n",
    "            x_flat = x.reshape(-1, D)\n",
    "            x_phi_flat = mlp_phi(x_flat)  # [B * N_particles, output_dim]\n",
    "            x_phi = x_phi_flat.reshape(B, N, self.output_dim)\n",
    "            summary = jnp.mean(x_phi, axis=1)  # [B, output_dim]\n",
    "        else:\n",
    "            raise ValueError(f\"Input must be of shape (N, D) or (B, N, D), got {x.shape}\")\n",
    "\n",
    "        return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3481ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressor = hk.transform_with_state(\n",
    "    lambda y: DeepSetsEncoder(compress_dim)(y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0ebbc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRAIN\n",
    "# init compressor\n",
    "parameters_SetNet, opt_state_SetNet = compressor.init(\n",
    "    jax.random.PRNGKey(0), y=jnp.ones([1, N_particles, 6])\n",
    ")\n",
    "\n",
    "# init nf\n",
    "params_nf = nf.init(\n",
    "    jax.random.PRNGKey(0), theta=0.5 * jnp.ones([1, 5]), y=0.5 * jnp.ones([1, dim])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f41b87b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = hk.data_structures.merge(parameters_SetNet, params_nf)\n",
    "\n",
    "# x = jnp.ones((1, N_particles, 6))\n",
    "# theta = jnp.ones((1, 5))\n",
    "\n",
    "# y, opt_state_resnet = compressor.apply(params, opt_state_SetNet, None, x)\n",
    "# print(y)\n",
    "# log_prob = nf.apply(params, theta, y)\n",
    "# print(log_prob)\n",
    "\n",
    "# print(-jnp.mean(log_prob), opt_state_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88414f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.loss[0] == \"train_compressor_vmim\":\n",
    "    parameters_compressor = hk.data_structures.merge(parameters_SetNet, params_nf)\n",
    "elif args.loss[0] in [\n",
    "    \"train_compressor_mse\",\n",
    "    \"train_compressor_mae\",\n",
    "    \"train_compressor_gnll\",\n",
    "]:\n",
    "    parameters_compressor = parameters_SetNet\n",
    "\n",
    "\n",
    "# define optimizer\n",
    "total_steps = args.total_steps[0]\n",
    "\n",
    "if args.loss == \"train_compressor_gnll\":\n",
    "    start_lr = 0.0001\n",
    "\n",
    "else:\n",
    "    start_lr = 0.001\n",
    "\n",
    "lr_scheduler = optax.piecewise_constant_schedule(\n",
    "    init_value=start_lr,\n",
    "    boundaries_and_scales={\n",
    "        int(total_steps * 0.1): 0.7,\n",
    "        int(total_steps * 0.2): 0.7,\n",
    "        int(total_steps * 0.3): 0.7,\n",
    "        int(total_steps * 0.4): 0.7,\n",
    "        int(total_steps * 0.5): 0.7,\n",
    "        int(total_steps * 0.6): 0.7,\n",
    "        int(total_steps * 0.7): 0.7,\n",
    "        int(total_steps * 0.8): 0.7,\n",
    "        int(total_steps * 0.9): 0.7,\n",
    "    },\n",
    ")\n",
    "\n",
    "optimizer_c = optax.adam(learning_rate=lr_scheduler)\n",
    "opt_state_c = optimizer_c.init(parameters_compressor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d0e6f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_compressor = TrainModel(\n",
    "    compressor=compressor,\n",
    "    nf=nf,\n",
    "    optimizer=optimizer_c,\n",
    "    loss_name=args.loss[0],\n",
    ")\n",
    "\n",
    "\n",
    "update = jax.jit(model_compressor.update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe9793d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: [5.2568798e+00 5.0465012e+04 1.0516200e+00 9.9948613e+11 1.0474024e+01], std: [2.7393756e+00 2.8652584e+04 5.5082726e-01 2.8847882e+11 5.4957938e+00]\n",
      "mean: [ 1.0705898e-02  1.4870495e-03 -1.9674072e-02  2.4276490e+00\n",
      " -2.1983453e-03  7.1738102e-02], std: [5.95247373e-02 3.69409740e-01 8.38953137e-01 1.04919624e+02\n",
      " 3.17265660e-01 4.72085744e-01]\n",
      "mean: [ 1.2090281e+01 -3.7612926e-06  1.0096312e+00  7.7777201e-10\n",
      " -5.5790531e+01], std: [1.7549825e+03 1.8628102e-03 9.5802881e+03 9.3244665e-08 1.0320980e+04]\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "data_path = '/export/data/vgiusepp/odisseo_data/data/data_NFW/'\n",
    "pattern = re.compile(r\"chunk_(\\d+)\\.npz\")  # capture any number of digits\n",
    "files = sorted(\n",
    "    f for f in Path(data_path).glob(\"chunk_*.npz\")\n",
    "    if (m := pattern.fullmatch(f.name)) and int(m.group(1)) < 70_000\n",
    ")\n",
    "theta_list, x_list, score_list = [], [], []\n",
    "\n",
    "for f in files:\n",
    "    data = np.load(f)\n",
    "    theta_list.append(data[\"theta\"])\n",
    "    x_list.append(data[\"x\"])\n",
    "    score_list.append(data[\"score\"]) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#remove nan values from theta\n",
    "dataset_theta = np.array(theta_list)\n",
    "mask_theta = ~np.isnan(dataset_theta).any(axis=(1))\n",
    "\n",
    "dataset_y = np.array(x_list)\n",
    "mask_y = ~np.isnan(dataset_y).any(axis=(1, 2))\n",
    "\n",
    "dataset_score = np.stack(score_list)\n",
    "mask_score = ~np.isnan(dataset_score).any(axis=(1))\n",
    "\n",
    "#combine the mask \n",
    "total_mask = mask_theta & mask_y & mask_score\n",
    "dataset_theta = dataset_theta[total_mask]\n",
    "dataset_y = dataset_y[total_mask]\n",
    "dataset_score = dataset_score[total_mask]\n",
    "\n",
    "\n",
    "\n",
    "#normalization function\n",
    "# @partial(jax.jit, static_argnums=(1,2))\n",
    "def normalize(dataset, is_observable = False, dataset_name = None):\n",
    "    if is_observable:\n",
    "        # the shape in this case is (N, N_particles, 6)\n",
    "        dataset_original_shape = dataset.shape\n",
    "        normalized_dataset = dataset.reshape(-1, dataset.shape[-1])\n",
    "        mean = np.mean(normalized_dataset, axis=0)\n",
    "        std = np.std(normalized_dataset, axis=0)\n",
    "        normalized_dataset = (normalized_dataset - mean)/ (std + 1e-8) \n",
    "        normalized_dataset = normalized_dataset.reshape(dataset_original_shape)\n",
    "    else:\n",
    "        mean = np.mean(dataset, axis=0)\n",
    "        std = np.std(dataset, axis=0)\n",
    "        normalized_dataset = (dataset - mean)/ (std + 1e-8) \n",
    "\n",
    "    print(f\"mean: {mean}, std: {std}\")\n",
    "    \n",
    "    if dataset_name is not None:\n",
    "        jnp.savez(\n",
    "            f\"./params_compressor/normalization_for_compressor_{dataset_name}.npz\",\n",
    "            mean=mean,\n",
    "            std=std,\n",
    "        )\n",
    "\n",
    "    return normalized_dataset\n",
    "\n",
    "training_set_compress_network = 40_000\n",
    "\n",
    "dataset_theta = normalize(dataset_theta[:training_set_compress_network], dataset_name=\"theta\")\n",
    "dataset_y = normalize(dataset_y[:training_set_compress_network], is_observable=True, dataset_name=\"y\")\n",
    "dataset_score = normalize(dataset_score[:training_set_compress_network], dataset_name=\"score\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "709507d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss -267.042: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [02:18<00:00, 27.62s/it]\n"
     ]
    }
   ],
   "source": [
    "total_steps = 5\n",
    "pbar = tqdm(range(total_steps))\n",
    "store_loss = []\n",
    "len_dataset = len(dataset_theta)\n",
    "index = np.arange(len_dataset)\n",
    "batch_size = 128\n",
    "for i in pbar:\n",
    "    np.random.shuffle(index)\n",
    "    for start_idx in range(0, len_dataset, batch_size):\n",
    "        end_idx = start_idx + batch_size\n",
    "        batch_indices = index[start_idx:end_idx]\n",
    "        batch = batch_indices\n",
    "        # batch = np.random.randint(0, len(dataset_theta), 5) #needs to be checked\n",
    "        theta = jnp.array(dataset_theta[batch])\n",
    "        x = jnp.array(dataset_y[batch])\n",
    "        score = jnp.array(dataset_score[batch])\n",
    "        # print(f\"theta: {theta.shape}, x: {x.shape}, score: {score.shape}\")\n",
    "        if not jnp.isnan(score).any():\n",
    "            b_loss, parameters_compressor, opt_state_c, opt_state_SetNet = update(\n",
    "                model_params=parameters_compressor,\n",
    "                opt_state=opt_state_c,\n",
    "                theta=theta,\n",
    "                x=x,\n",
    "                state_resnet=opt_state_SetNet,\n",
    "            )\n",
    "            store_loss.append(b_loss)\n",
    "            pbar.set_description(f\"loss {b_loss:.3f}\")\n",
    "\n",
    "            if jnp.isnan(b_loss):\n",
    "                print(\"NaN Loss\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bea19ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(store_loss)\n",
    "plt.xlabel(\"Batch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "# plt.yscale('log')\n",
    "# plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f187e57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the compressor \n",
    "\n",
    "compress_data, _ = compressor.apply(\n",
    "    parameters_compressor, opt_state_SetNet, None, dataset_y[:2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "540fd50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compress_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e50cfe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model \n",
    "import pickle\n",
    "\n",
    "with open(\n",
    "    \"./params_compressor/params_nd_compressor_vmim.pkl\", \"wb\"\n",
    ") as fp:\n",
    "    pickle.dump(parameters_compressor, fp)\n",
    "\n",
    "with open(\"./params_compressor/opt_state_SetNet_vmim.pkl\", \"wb\") as fp:\n",
    "    pickle.dump(opt_state_SetNet, fp)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac1754c",
   "metadata": {},
   "source": [
    "# Batch not loaded in memeory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "329648da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_file(file_path):\n",
    "    # Replace with your actual loading logic (e.g., np.load, h5py, etc.)\n",
    "    return np.load(file_path)\n",
    "\n",
    "def data_generator(file_paths, batch_size, name, shuffle=True, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    if shuffle:\n",
    "        rng.shuffle(file_paths)\n",
    "    for i in range(0, len(file_paths), batch_size):\n",
    "        batch_paths = file_paths[i:i+batch_size]\n",
    "        batch = [load_file(p)[name] for p in batch_paths]\n",
    "        yield np.stack(batch)\n",
    "\n",
    "\n",
    "def compute_mean_std(file_paths, batch_size, name):\n",
    "    count = 0\n",
    "    mean = None\n",
    "    M2 = None  # Sum of squares of differences from the current mean\n",
    "\n",
    "    for batch in data_generator(file_paths, batch_size, name, shuffle=False):\n",
    "\n",
    "        if name == \"x\":\n",
    "            print(batch.shape)\n",
    "            batch = batch.reshape(-1, 6)\n",
    "            # x = batch[:, :-1]\n",
    "            x = batch\n",
    "            print(x.shape)\n",
    "        else:\n",
    "            # x = batch[:, :-1]  # assuming last column is target\n",
    "            x = batch\n",
    "\n",
    "        if mean is None:\n",
    "            mean = np.zeros(x.shape[1])\n",
    "            M2 = np.zeros(x.shape[1])\n",
    "    \n",
    "        batch_count = x.shape[0]\n",
    "        batch_mean = np.mean(x, axis=0)\n",
    "        batch_var = np.var(x, axis=0)\n",
    "\n",
    "        delta = batch_mean - mean\n",
    "        total_count = count + batch_count\n",
    "\n",
    "        mean += delta * batch_count / total_count\n",
    "        M2 += batch_var * batch_count + (delta**2) * count * batch_count / total_count\n",
    "\n",
    "        count = total_count\n",
    "    \n",
    "    variance = M2 / count\n",
    "    std = np.sqrt(variance)\n",
    "    return mean, std\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ab8017f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      3\u001b[39m pattern = re.compile(\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mchunk_(\u001b[39m\u001b[33m\\\u001b[39m\u001b[33md+)\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m.npz\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# capture any number of digits\u001b[39;00m\n\u001b[32m      4\u001b[39m files = \u001b[38;5;28msorted\u001b[39m(\n\u001b[32m      5\u001b[39m     f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m Path(data_path).glob(\u001b[33m\"\u001b[39m\u001b[33mchunk_*.npz\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (m := pattern.fullmatch(f.name)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mint\u001b[39m(m.group(\u001b[32m1\u001b[39m)) < \u001b[32m1_000\u001b[39m\n\u001b[32m      7\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m mean, std = \u001b[43mcompute_mean_std\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 51\u001b[39m, in \u001b[36mcompute_mean_std\u001b[39m\u001b[34m(file_paths, batch_size, name)\u001b[39m\n\u001b[32m     47\u001b[39m     M2 += batch_var * batch_count + (delta**\u001b[32m2\u001b[39m) * count * batch_count / total_count\n\u001b[32m     49\u001b[39m     count = total_count\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m variance = \u001b[43mM2\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\n\u001b[32m     52\u001b[39m std = np.sqrt(variance)\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m mean, std\n",
      "\u001b[31mTypeError\u001b[39m: unsupported operand type(s) for /: 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "data_path = './data/data_NFW/'\n",
    "pattern = re.compile(r\"chunk_(\\d+)\\.npz\")  # capture any number of digits\n",
    "files = sorted(\n",
    "    f for f in Path(data_path).glob(\"chunk_*.npz\")\n",
    "    if (m := pattern.fullmatch(f.name)) and int(m.group(1)) < 1_000\n",
    ")\n",
    "\n",
    "mean, std = compute_mean_std(files, batch_size=1000, name=\"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ed2652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.94607902e-02, 7.02848422e-01, 1.75719736e+00, 1.77413414e+02,\n",
       "       4.31594656e-01, 7.39438316e-01])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76ed47f",
   "metadata": {},
   "source": [
    "mean: [ 0.01226011 -0.02244665  0.09708447 -2.625139    0.01436208  0.09414793], std: [9.9460788e-02 7.0284843e-01 1.7571974e+00 1.7741342e+02 4.3159467e-01\n",
    " 7.3943830e-01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfcfc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def update_vectorized(count, mean, M2, batch):\n",
    "    \"\"\"\n",
    "    Vectorized Welford update.\n",
    "    - count: scalar (number of samples seen so far)\n",
    "    - mean: array of shape (D,)\n",
    "    - M2: array of shape (D,)\n",
    "    - batch: shape (B, D)\n",
    "    Returns updated (count, mean, M2)\n",
    "    \"\"\"\n",
    "    batch_count = batch.shape[0]\n",
    "    batch_mean = np.mean(batch, axis=0)\n",
    "    batch_M2 = np.sum((batch - batch_mean) ** 2, axis=0)\n",
    "\n",
    "    if count == 0:\n",
    "        # First batch: initialize\n",
    "        return batch_count, batch_mean, batch_M2\n",
    "\n",
    "    delta = batch_mean - mean\n",
    "    new_count = count + batch_count\n",
    "    new_mean = mean + delta * batch_count / new_count\n",
    "    new_M2 = M2 + batch_M2 + (delta**2) * count * batch_count / new_count\n",
    "\n",
    "    return new_count, new_mean, new_M2\n",
    "\n",
    "def finalize_vectorized(count, mean, M2):\n",
    "    if count < 2:\n",
    "        raise ValueError(\"At least two samples required.\")\n",
    "    var = M2 / count\n",
    "    std = np.sqrt(var)\n",
    "    return mean, var, std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4dc62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume all batches have shape (batch_size, num_features)\n",
    "def compute_mean_std(file_paths, batch_size, name):\n",
    "    initial_count = 0\n",
    "    initial_mean = np.zeros(6)\n",
    "    initial_M2 = np.zeros(6)\n",
    "\n",
    "    aggregate = (initial_count, initial_mean, initial_M2)\n",
    "\n",
    "    for batch in data_generator(file_paths, batch_size, name, shuffle=False):\n",
    "        if name == \"x\":\n",
    "            batch = batch.reshape(-1, 6)\n",
    "        aggregate = update_vectorized(aggregate, batch)\n",
    "\n",
    "    mean, var, sample_var = finalize_vectorized(aggregate)\n",
    "    std = np.sqrt(var)\n",
    "\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3329a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "update_vectorized() missing 2 required positional arguments: 'M2' and 'batch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mcompute_mean_std\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mcompute_mean_std\u001b[39m\u001b[34m(file_paths, batch_size, name)\u001b[39m\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name == \u001b[33m\"\u001b[39m\u001b[33mx\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     11\u001b[39m         batch = batch.reshape(-\u001b[32m1\u001b[39m, \u001b[32m6\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     aggregate = \u001b[43mupdate_vectorized\u001b[49m\u001b[43m(\u001b[49m\u001b[43maggregate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m mean, var, sample_var = finalize_vectorized(aggregate)\n\u001b[32m     15\u001b[39m std = np.sqrt(var)\n",
      "\u001b[31mTypeError\u001b[39m: update_vectorized() missing 2 required positional arguments: 'M2' and 'batch'"
     ]
    }
   ],
   "source": [
    "compute_mean_std(files, batch_size=1000, name=\"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba65fe89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: [ 0.01226027 -0.02244593  0.0970807  -2.62586575  0.0143615   0.09415632]\n",
      "Std: [1.00233859e-01 7.06850254e-01 1.76492770e+00 1.78132901e+02\n",
      " 4.36402014e-01 7.47493294e-01]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ---------- Welfordâ€™s vectorized update ----------\n",
    "def update_vectorized(count, mean, M2, batch):\n",
    "    batch_count = batch.shape[0]\n",
    "    batch_mean = np.mean(batch, axis=0)\n",
    "    batch_M2 = np.sum((batch - batch_mean) ** 2, axis=0)\n",
    "\n",
    "    if count == 0:\n",
    "        return batch_count, batch_mean, batch_M2\n",
    "\n",
    "    delta = batch_mean - mean\n",
    "    new_count = count + batch_count\n",
    "    new_mean = mean + delta * batch_count / new_count\n",
    "    new_M2 = M2 + batch_M2 + (delta**2) * count * batch_count / new_count\n",
    "\n",
    "    return new_count, new_mean, new_M2\n",
    "\n",
    "def finalize_vectorized(count, mean, M2):\n",
    "    if count < 2:\n",
    "        raise ValueError(\"At least two samples required.\")\n",
    "    var = M2 / count\n",
    "    std = np.sqrt(var)\n",
    "    return mean, var, std\n",
    "\n",
    "\n",
    "count = 0\n",
    "mean = None\n",
    "M2 = None\n",
    "\n",
    "for batch in data_generator(files, batch_size=64, name=\"x\"):\n",
    "    batch = batch.reshape(-1, 6)\n",
    "    if count == 0:\n",
    "        count, mean, M2 = update_vectorized(0, None, None, batch)\n",
    "    else:\n",
    "        count, mean, M2 = update_vectorized(count, mean, M2, batch)\n",
    "\n",
    "final_mean, final_var, final_std = finalize_vectorized(count, mean, M2)\n",
    "\n",
    "print(\"Mean:\", final_mean)\n",
    "print(\"Std:\", final_std)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05785925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f63c907",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbi_ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
