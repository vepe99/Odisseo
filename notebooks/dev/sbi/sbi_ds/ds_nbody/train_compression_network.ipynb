{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "107c77d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 16:01:21.675325: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747058481.708257 3952262 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747058481.718122 3952262 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1747058481.743510 3952262 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747058481.743561 3952262 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747058481.743564 3952262 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747058481.743566 3952262 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "# from autocvd import autocvd\n",
    "# autocvd(num_gpus = 1)\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import jit\n",
    "import optax\n",
    "import haiku as hk\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from tensorflow_probability.substrates import jax as tfp\n",
    "tfb = tfp.bijectors\n",
    "tfd = tfp.distributions\n",
    "\n",
    "\n",
    "from normflow_models import (AffineCoupling,\n",
    "                             AffineSigmoidCoupling,\n",
    "                             ConditionalRealNVP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02a5bb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class to Train the compressor, in our case we are going to train \n",
    "#the compressor with the vmim, so we will also need a Normalizing Flow \n",
    "#  which is going to be trained with the compressor\n",
    "\n",
    "class TrainModel:\n",
    "    def __init__(\n",
    "        self,\n",
    "        compressor,\n",
    "        nf,\n",
    "        optimizer,\n",
    "        loss_name,\n",
    "        dim=None,\n",
    "        info_compressor=None,\n",
    "    ):\n",
    "        self.compressor = compressor\n",
    "        self.nf = nf\n",
    "        self.optimizer = optimizer\n",
    "        self.dim = dim  # summary statistic dimension\n",
    "\n",
    "        if loss_name == \"train_compressor_mse\":\n",
    "            self.loss = self.loss_mse\n",
    "        elif loss_name == \"train_compressor_vmim\":\n",
    "            self.loss = self.loss_vmim\n",
    "        elif loss_name == \"train_compressor_gnll\":\n",
    "            self.loss = self.loss_gnll\n",
    "            if self.dim is None:\n",
    "                raise ValueError(\"dim should be specified when using gnll compressor\")\n",
    "        elif loss_name == \"loss_for_sbi\":\n",
    "            if info_compressor is None:\n",
    "                raise ValueError(\"sbi loss needs compressor informations\")\n",
    "            else:\n",
    "                self.info_compressor = info_compressor\n",
    "                self.loss = self.loss_nll\n",
    "\n",
    "    def loss_mse(self, params, theta, x, state_resnet):\n",
    "        \"\"\"Compute the Mean Squared Error loss\"\"\"\n",
    "        y, opt_state_resnet = self.compressor.apply(params, state_resnet, None, x)\n",
    "\n",
    "        loss = jnp.mean(jnp.sum((y - theta) ** 2, axis=1))\n",
    "\n",
    "        return loss, opt_state_resnet\n",
    "\n",
    "    def loss_mae(self, params, theta, x, state_resnet):\n",
    "        \"\"\"Compute the Mean Absolute Error loss\"\"\"\n",
    "        y, opt_state_resnet = self.compressor.apply(params, state_resnet, None, x)\n",
    "\n",
    "        loss = jnp.mean(jnp.sum(jnp.absolute(y - theta), axis=1))\n",
    "\n",
    "        return loss, opt_state_resnet\n",
    "\n",
    "    def loss_vmim(self, params, theta, x, state_resnet):\n",
    "        \"\"\"Compute the Variational Mutual Information Maximization loss\"\"\"\n",
    "        y, opt_state_resnet = self.compressor.apply(params, state_resnet, None, x)\n",
    "        log_prob = self.nf.apply(params, theta, y)\n",
    "\n",
    "        return -jnp.mean(log_prob), opt_state_resnet\n",
    "\n",
    "    def loss_gnll(self, params, theta, x, state_resnet):\n",
    "        \"\"\"Compute the Gaussian Negative Log Likelihood loss\"\"\"\n",
    "        y, opt_state_resnet = self.compressor.apply(params, state_resnet, None, x)\n",
    "        y_mean = y[..., : self.dim]\n",
    "        y_var = y[..., self.dim :]\n",
    "        y_var = tfb.FillScaleTriL(diag_bijector=tfb.Softplus(low=1e-3)).forward(y_var)\n",
    "\n",
    "        @jax.jit\n",
    "        @jax.vmap\n",
    "        def _get_log_prob(y_mean, y_var, theta):\n",
    "            likelihood = tfd.MultivariateNormalTriL(y_mean, y_var)\n",
    "            return likelihood.log_prob(theta)\n",
    "\n",
    "        loss = -jnp.mean(_get_log_prob(y_mean, y_var, theta))\n",
    "\n",
    "        return loss, opt_state_resnet\n",
    "\n",
    "    def loss_nll(self, params, theta, x, _):\n",
    "        \"\"\"Compute the Negative Log Likelihood loss.\n",
    "        This loss is for inference so it requires to have a trained compressor.\n",
    "        \"\"\"\n",
    "        y, _ = self.compressor.apply(\n",
    "            self.info_compressor[0], self.info_compressor[1], None, x\n",
    "        )\n",
    "        log_prob = self.nf.apply(params, theta, y)\n",
    "\n",
    "        return -jnp.mean(log_prob), _\n",
    "\n",
    "    @partial(jax.jit, static_argnums=(0,))\n",
    "    def update(self, model_params, opt_state, theta, x, state_resnet=None):\n",
    "        (loss, opt_state_resnet), grads = jax.value_and_grad(self.loss, has_aux=True)(\n",
    "            model_params, theta, x, state_resnet\n",
    "        )\n",
    "\n",
    "        updates, new_opt_state = self.optimizer.update(grads, opt_state)\n",
    "\n",
    "        new_params = optax.apply_updates(model_params, updates)\n",
    "\n",
    "        return loss, new_params, new_opt_state, opt_state_resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36dabbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "#mimic the argument parser used in the sbi_bm_lens\n",
    "\n",
    "class args_namedtuple(NamedTuple):\n",
    "\n",
    "    total_steps = 4500,\n",
    "\n",
    "    loss = \"train_compressor_vmim\",\n",
    "    # loss = \"train_compressor_mse\",\n",
    "\n",
    "\n",
    "args = args_namedtuple()\n",
    "dim = 128\n",
    "N_particles = 10_000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17114efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### create compressor \n",
    "\n",
    "#nf \n",
    "bijector_layers_compressor = [128] * 2\n",
    "\n",
    "bijector_compressor = partial(\n",
    "    AffineCoupling, layers=bijector_layers_compressor, activation=jax.nn.silu\n",
    ")\n",
    "\n",
    "NF_compressor = partial(ConditionalRealNVP, n_layers=4, bijector_fn=bijector_compressor)\n",
    "\n",
    "\n",
    "class Flow_nd_Compressor(hk.Module):\n",
    "    def __call__(self, y):\n",
    "        nvp = NF_compressor(dim)(y)\n",
    "        return nvp\n",
    "\n",
    "\n",
    "nf = hk.without_apply_rng(\n",
    "    hk.transform(lambda theta, y: Flow_nd_Compressor()(theta).log_prob(y).squeeze())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03cdfdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.loss == \"train_compressor_gnll\":\n",
    "    compress_dim = int(dim + ((dim**2) - dim) / 2 + dim)\n",
    "else:\n",
    "    compress_dim = dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "045c7918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DeepSetsEncoder(hk.Module):\n",
    "#     def __init__(self, output_dim, hidden_dim: int = 128, name=None):\n",
    "#         super().__init__(name=name)\n",
    "#         self.hidden_dim = hidden_dim\n",
    "#         self.output_dim = output_dim\n",
    "\n",
    "#     def __call__(self, x):  # x: [N_particles, 6]\n",
    "#         # Ï† network: shared across all particles\n",
    "#         mlp_phi = hk.nets.MLP([self.hidden_dim, self.hidden_dim, self.output_dim])\n",
    "#         x_phi = mlp_phi(x)  # shape: [N_particles, output_dim]\n",
    "\n",
    "#         # Pooling over the set dimension (e.g., mean, sum)\n",
    "#         summary = jnp.mean(x_phi, axis=0)  # shape: [output_dim]\n",
    "\n",
    "#         return summary\n",
    "\n",
    "\n",
    "class DeepSetsEncoder(hk.Module):\n",
    "    def __init__(self, output_dim, hidden_dim: int = 128, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def __call__(self, x):  # x: [N_particles, 6] or [B, N_particles, 6]\n",
    "        mlp_phi = hk.nets.MLP([self.hidden_dim, self.hidden_dim, self.hidden_dim, self.output_dim])\n",
    "\n",
    "        if x.ndim == 2:\n",
    "            # Unbatched case: [N_particles, 6]\n",
    "            x_phi = mlp_phi(x)  # [N_particles, output_dim]\n",
    "            summary = jnp.mean(x_phi, axis=0)  # [output_dim]\n",
    "        elif x.ndim == 3:\n",
    "            # Batched case: [B, N_particles, 6]\n",
    "            # Flatten for MLP: [B * N_particles, 6]\n",
    "            B, N, D = x.shape\n",
    "            x_flat = x.reshape(-1, D)\n",
    "            x_phi_flat = mlp_phi(x_flat)  # [B * N_particles, output_dim]\n",
    "            x_phi = x_phi_flat.reshape(B, N, self.output_dim)\n",
    "            summary = jnp.mean(x_phi, axis=1)  # [B, output_dim]\n",
    "        else:\n",
    "            raise ValueError(f\"Input must be of shape (N, D) or (B, N, D), got {x.shape}\")\n",
    "\n",
    "        return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3481ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressor = hk.transform_with_state(\n",
    "    lambda y: DeepSetsEncoder(compress_dim)(y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0ebbc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRAIN\n",
    "# init compressor\n",
    "parameters_SetNet, opt_state_SetNet = compressor.init(\n",
    "    jax.random.PRNGKey(0), y=jnp.ones([1, N_particles, 6])\n",
    ")\n",
    "\n",
    "# init nf\n",
    "params_nf = nf.init(\n",
    "    jax.random.PRNGKey(0), theta=0.5 * jnp.ones([1, 5]), y=0.5 * jnp.ones([1, dim])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f41b87b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = hk.data_structures.merge(parameters_SetNet, params_nf)\n",
    "\n",
    "# x = jnp.ones((1, N_particles, 6))\n",
    "# theta = jnp.ones((1, 5))\n",
    "\n",
    "# y, opt_state_resnet = compressor.apply(params, opt_state_SetNet, None, x)\n",
    "# print(y)\n",
    "# log_prob = nf.apply(params, theta, y)\n",
    "# print(log_prob)\n",
    "\n",
    "# print(-jnp.mean(log_prob), opt_state_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88414f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.loss[0] == \"train_compressor_vmim\":\n",
    "    parameters_compressor = hk.data_structures.merge(parameters_SetNet, params_nf)\n",
    "elif args.loss[0] in [\n",
    "    \"train_compressor_mse\",\n",
    "    \"train_compressor_mae\",\n",
    "    \"train_compressor_gnll\",\n",
    "]:\n",
    "    parameters_compressor = parameters_SetNet\n",
    "\n",
    "\n",
    "# define optimizer\n",
    "total_steps = args.total_steps[0]\n",
    "\n",
    "if args.loss == \"train_compressor_gnll\":\n",
    "    start_lr = 0.0001\n",
    "\n",
    "else:\n",
    "    start_lr = 0.001\n",
    "\n",
    "lr_scheduler = optax.piecewise_constant_schedule(\n",
    "    init_value=start_lr,\n",
    "    boundaries_and_scales={\n",
    "        int(total_steps * 0.1): 0.7,\n",
    "        int(total_steps * 0.2): 0.7,\n",
    "        int(total_steps * 0.3): 0.7,\n",
    "        int(total_steps * 0.4): 0.7,\n",
    "        int(total_steps * 0.5): 0.7,\n",
    "        int(total_steps * 0.6): 0.7,\n",
    "        int(total_steps * 0.7): 0.7,\n",
    "        int(total_steps * 0.8): 0.7,\n",
    "        int(total_steps * 0.9): 0.7,\n",
    "    },\n",
    ")\n",
    "\n",
    "optimizer_c = optax.adam(learning_rate=lr_scheduler)\n",
    "opt_state_c = optimizer_c.init(parameters_compressor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d0e6f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_compressor = TrainModel(\n",
    "    compressor=compressor,\n",
    "    nf=nf,\n",
    "    optimizer=optimizer_c,\n",
    "    loss_name=args.loss[0],\n",
    ")\n",
    "\n",
    "\n",
    "update = jax.jit(model_compressor.update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe9793d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: [5.2568798e+00 5.0465012e+04 1.0516200e+00 9.9948613e+11 1.0474024e+01], std: [2.7393756e+00 2.8652584e+04 5.5082726e-01 2.8847882e+11 5.4957938e+00]\n",
      "mean: [ 1.0705898e-02  1.4870495e-03 -1.9674072e-02  2.4276490e+00\n",
      " -2.1983453e-03  7.1738102e-02], std: [5.95247373e-02 3.69409740e-01 8.38953137e-01 1.04919624e+02\n",
      " 3.17265660e-01 4.72085744e-01]\n",
      "mean: [ 1.2090281e+01 -3.7612926e-06  1.0096312e+00  7.7777201e-10\n",
      " -5.5790531e+01], std: [1.7549825e+03 1.8628102e-03 9.5802881e+03 9.3244665e-08 1.0320980e+04]\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "data_path = '/export/data/vgiusepp/odisseo_data/data/data_NFW/'\n",
    "pattern = re.compile(r\"chunk_(\\d+)\\.npz\")  # capture any number of digits\n",
    "files = sorted(\n",
    "    f for f in Path(data_path).glob(\"chunk_*.npz\")\n",
    "    if (m := pattern.fullmatch(f.name)) and int(m.group(1)) < 100_000\n",
    ")\n",
    "theta_list, x_list, score_list = [], [], []\n",
    "\n",
    "for f in files:\n",
    "    data = np.load(f)\n",
    "    theta_list.append(data[\"theta\"])\n",
    "    x_list.append(data[\"x\"])\n",
    "    score_list.append(data[\"score\"]) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#remove nan values from theta\n",
    "dataset_theta = np.array(theta_list)\n",
    "mask_theta = ~np.isnan(dataset_theta).any(axis=(1))\n",
    "\n",
    "dataset_y = np.array(x_list)\n",
    "mask_y = ~np.isnan(dataset_y).any(axis=(1, 2))\n",
    "\n",
    "dataset_score = np.stack(score_list)\n",
    "mask_score = ~np.isnan(dataset_score).any(axis=(1))\n",
    "\n",
    "#combine the mask \n",
    "total_mask = mask_theta & mask_y & mask_score\n",
    "dataset_theta = dataset_theta[total_mask]\n",
    "dataset_y = dataset_y[total_mask]\n",
    "dataset_score = dataset_score[total_mask]\n",
    "\n",
    "\n",
    "\n",
    "#normalization function\n",
    "# @partial(jax.jit, static_argnums=(1,2))\n",
    "def normalize(dataset, is_observable = False, dataset_name = None):\n",
    "    if is_observable:\n",
    "        # the shape in this case is (N, N_particles, 6)\n",
    "        dataset_original_shape = dataset.shape\n",
    "        normalized_dataset = dataset.reshape(-1, dataset.shape[-1])\n",
    "        mean = np.mean(normalized_dataset, axis=0)\n",
    "        std = np.std(normalized_dataset, axis=0)\n",
    "        normalized_dataset = (normalized_dataset - mean)/ (std + 1e-8) \n",
    "        normalized_dataset = normalized_dataset.reshape(dataset_original_shape)\n",
    "    else:\n",
    "        mean = np.mean(dataset, axis=0)\n",
    "        std = np.std(dataset, axis=0)\n",
    "        normalized_dataset = (dataset - mean)/ (std + 1e-8) \n",
    "\n",
    "    print(f\"mean: {mean}, std: {std}\")\n",
    "    \n",
    "    if dataset_name is not None:\n",
    "        jnp.savez(\n",
    "            f\"./params_compressor/normalization_for_compressor_{dataset_name}.npz\",\n",
    "            mean=mean,\n",
    "            std=std,\n",
    "        )\n",
    "\n",
    "    return normalized_dataset\n",
    "\n",
    "training_set_compress_network = 40_000\n",
    "\n",
    "dataset_theta = dataset_theta[:training_set_compress_network]\n",
    "dataset_y = dataset_y[:training_set_compress_network]\n",
    "dataset_score = dataset_score[:training_set_compress_network]\n",
    "\n",
    "dataset_theta = normalize(dataset_theta, dataset_name=\"theta\")\n",
    "dataset_y = normalize(dataset_y, is_observable=True, dataset_name=\"y\")\n",
    "dataset_score = normalize(dataset_score, dataset_name=\"score\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "709507d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss -613.080: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [02:18<00:00, 27.73s/it]\n"
     ]
    }
   ],
   "source": [
    "total_steps = 5\n",
    "pbar = tqdm(range(total_steps))\n",
    "store_loss = []\n",
    "len_dataset = len(dataset_theta)\n",
    "index = np.arange(len_dataset)\n",
    "batch_size = 128\n",
    "for i in pbar:\n",
    "    np.random.shuffle(index)\n",
    "    for start_idx in range(0, len_dataset, batch_size):\n",
    "        end_idx = start_idx + batch_size\n",
    "        batch_indices = index[start_idx:end_idx]\n",
    "        batch = batch_indices\n",
    "        # batch = np.random.randint(0, len(dataset_theta), 5) #needs to be checked\n",
    "        theta = jnp.array(dataset_theta[batch])\n",
    "        x = jnp.array(dataset_y[batch])\n",
    "        score = jnp.array(dataset_score[batch])\n",
    "        # print(f\"theta: {theta.shape}, x: {x.shape}, score: {score.shape}\")\n",
    "        if not jnp.isnan(score).any():\n",
    "            b_loss, parameters_compressor, opt_state_c, opt_state_SetNet = update(\n",
    "                model_params=parameters_compressor,\n",
    "                opt_state=opt_state_c,\n",
    "                theta=theta,\n",
    "                x=x,\n",
    "                state_resnet=opt_state_SetNet,\n",
    "            )\n",
    "            store_loss.append(b_loss)\n",
    "            pbar.set_description(f\"loss {b_loss:.3f}\")\n",
    "\n",
    "            if jnp.isnan(b_loss):\n",
    "                print(\"NaN Loss\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bea19ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(store_loss)\n",
    "plt.xlabel(\"Batch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "# plt.yscale('log')\n",
    "# plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f187e57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the compressor \n",
    "\n",
    "compress_data, _ = compressor.apply(\n",
    "    parameters_compressor, opt_state_SetNet, None, dataset_y[:2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "540fd50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 128)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compress_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e50cfe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model \n",
    "import pickle\n",
    "\n",
    "with open(\n",
    "    \"./params_compressor/params_nd_compressor_vmim.pkl\", \"wb\"\n",
    ") as fp:\n",
    "    pickle.dump(parameters_compressor, fp)\n",
    "\n",
    "with open(\"./params_compressor/opt_state_SetNet_vmim.pkl\", \"wb\") as fp:\n",
    "    pickle.dump(opt_state_SetNet, fp)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac1754c",
   "metadata": {},
   "source": [
    "# Batch not loaded in memeory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "329648da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_file(file_path):\n",
    "    # Replace with your actual loading logic (e.g., np.load, h5py, etc.)\n",
    "    return np.load(file_path)\n",
    "\n",
    "def data_generator(file_paths, batch_size, name, shuffle=True, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    if shuffle:\n",
    "        rng.shuffle(file_paths)\n",
    "    for i in range(0, len(file_paths), batch_size):\n",
    "        batch_paths = file_paths[i:i+batch_size]\n",
    "        batch = [load_file(p)[name] for p in batch_paths]\n",
    "        yield np.stack(batch)\n",
    "\n",
    "\n",
    "def compute_mean_std(file_paths, batch_size, name):\n",
    "    count = 0\n",
    "    mean = None\n",
    "    M2 = None  # Sum of squares of differences from the current mean\n",
    "\n",
    "    for batch in data_generator(file_paths, batch_size, name, shuffle=False):\n",
    "\n",
    "        if name == \"x\":\n",
    "            print(batch.shape)\n",
    "            batch = batch.reshape(-1, 6)\n",
    "            # x = batch[:, :-1]\n",
    "            x = batch\n",
    "            print(x.shape)\n",
    "        else:\n",
    "            # x = batch[:, :-1]  # assuming last column is target\n",
    "            x = batch\n",
    "\n",
    "        if mean is None:\n",
    "            mean = np.zeros(x.shape[1])\n",
    "            M2 = np.zeros(x.shape[1])\n",
    "    \n",
    "        batch_count = x.shape[0]\n",
    "        batch_mean = np.mean(x, axis=0)\n",
    "        batch_var = np.var(x, axis=0)\n",
    "\n",
    "        delta = batch_mean - mean\n",
    "        total_count = count + batch_count\n",
    "\n",
    "        mean += delta * batch_count / total_count\n",
    "        M2 += batch_var * batch_count + (delta**2) * count * batch_count / total_count\n",
    "\n",
    "        count = total_count\n",
    "    \n",
    "    variance = M2 / count\n",
    "    std = np.sqrt(variance)\n",
    "    return mean, std\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ab8017f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      3\u001b[39m pattern = re.compile(\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mchunk_(\u001b[39m\u001b[33m\\\u001b[39m\u001b[33md+)\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m.npz\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# capture any number of digits\u001b[39;00m\n\u001b[32m      4\u001b[39m files = \u001b[38;5;28msorted\u001b[39m(\n\u001b[32m      5\u001b[39m     f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m Path(data_path).glob(\u001b[33m\"\u001b[39m\u001b[33mchunk_*.npz\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (m := pattern.fullmatch(f.name)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mint\u001b[39m(m.group(\u001b[32m1\u001b[39m)) < \u001b[32m1_000\u001b[39m\n\u001b[32m      7\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m mean, std = \u001b[43mcompute_mean_std\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 51\u001b[39m, in \u001b[36mcompute_mean_std\u001b[39m\u001b[34m(file_paths, batch_size, name)\u001b[39m\n\u001b[32m     47\u001b[39m     M2 += batch_var * batch_count + (delta**\u001b[32m2\u001b[39m) * count * batch_count / total_count\n\u001b[32m     49\u001b[39m     count = total_count\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m variance = \u001b[43mM2\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\n\u001b[32m     52\u001b[39m std = np.sqrt(variance)\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m mean, std\n",
      "\u001b[31mTypeError\u001b[39m: unsupported operand type(s) for /: 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "data_path = './data/data_NFW/'\n",
    "pattern = re.compile(r\"chunk_(\\d+)\\.npz\")  # capture any number of digits\n",
    "files = sorted(\n",
    "    f for f in Path(data_path).glob(\"chunk_*.npz\")\n",
    "    if (m := pattern.fullmatch(f.name)) and int(m.group(1)) < 1_000\n",
    ")\n",
    "\n",
    "mean, std = compute_mean_std(files, batch_size=1000, name=\"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ed2652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.94607902e-02, 7.02848422e-01, 1.75719736e+00, 1.77413414e+02,\n",
       "       4.31594656e-01, 7.39438316e-01])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76ed47f",
   "metadata": {},
   "source": [
    "mean: [ 0.01226011 -0.02244665  0.09708447 -2.625139    0.01436208  0.09414793], std: [9.9460788e-02 7.0284843e-01 1.7571974e+00 1.7741342e+02 4.3159467e-01\n",
    " 7.3943830e-01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfcfc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def update_vectorized(count, mean, M2, batch):\n",
    "    \"\"\"\n",
    "    Vectorized Welford update.\n",
    "    - count: scalar (number of samples seen so far)\n",
    "    - mean: array of shape (D,)\n",
    "    - M2: array of shape (D,)\n",
    "    - batch: shape (B, D)\n",
    "    Returns updated (count, mean, M2)\n",
    "    \"\"\"\n",
    "    batch_count = batch.shape[0]\n",
    "    batch_mean = np.mean(batch, axis=0)\n",
    "    batch_M2 = np.sum((batch - batch_mean) ** 2, axis=0)\n",
    "\n",
    "    if count == 0:\n",
    "        # First batch: initialize\n",
    "        return batch_count, batch_mean, batch_M2\n",
    "\n",
    "    delta = batch_mean - mean\n",
    "    new_count = count + batch_count\n",
    "    new_mean = mean + delta * batch_count / new_count\n",
    "    new_M2 = M2 + batch_M2 + (delta**2) * count * batch_count / new_count\n",
    "\n",
    "    return new_count, new_mean, new_M2\n",
    "\n",
    "def finalize_vectorized(count, mean, M2):\n",
    "    if count < 2:\n",
    "        raise ValueError(\"At least two samples required.\")\n",
    "    var = M2 / count\n",
    "    std = np.sqrt(var)\n",
    "    return mean, var, std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4dc62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume all batches have shape (batch_size, num_features)\n",
    "def compute_mean_std(file_paths, batch_size, name):\n",
    "    initial_count = 0\n",
    "    initial_mean = np.zeros(6)\n",
    "    initial_M2 = np.zeros(6)\n",
    "\n",
    "    aggregate = (initial_count, initial_mean, initial_M2)\n",
    "\n",
    "    for batch in data_generator(file_paths, batch_size, name, shuffle=False):\n",
    "        if name == \"x\":\n",
    "            batch = batch.reshape(-1, 6)\n",
    "        aggregate = update_vectorized(aggregate, batch)\n",
    "\n",
    "    mean, var, sample_var = finalize_vectorized(aggregate)\n",
    "    std = np.sqrt(var)\n",
    "\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3329a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "update_vectorized() missing 2 required positional arguments: 'M2' and 'batch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mcompute_mean_std\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mcompute_mean_std\u001b[39m\u001b[34m(file_paths, batch_size, name)\u001b[39m\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name == \u001b[33m\"\u001b[39m\u001b[33mx\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     11\u001b[39m         batch = batch.reshape(-\u001b[32m1\u001b[39m, \u001b[32m6\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     aggregate = \u001b[43mupdate_vectorized\u001b[49m\u001b[43m(\u001b[49m\u001b[43maggregate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m mean, var, sample_var = finalize_vectorized(aggregate)\n\u001b[32m     15\u001b[39m std = np.sqrt(var)\n",
      "\u001b[31mTypeError\u001b[39m: update_vectorized() missing 2 required positional arguments: 'M2' and 'batch'"
     ]
    }
   ],
   "source": [
    "compute_mean_std(files, batch_size=1000, name=\"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba65fe89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: [ 0.01226027 -0.02244593  0.0970807  -2.62586575  0.0143615   0.09415632]\n",
      "Std: [1.00233859e-01 7.06850254e-01 1.76492770e+00 1.78132901e+02\n",
      " 4.36402014e-01 7.47493294e-01]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ---------- Welfordâ€™s vectorized update ----------\n",
    "def update_vectorized(count, mean, M2, batch):\n",
    "    batch_count = batch.shape[0]\n",
    "    batch_mean = np.mean(batch, axis=0)\n",
    "    batch_M2 = np.sum((batch - batch_mean) ** 2, axis=0)\n",
    "\n",
    "    if count == 0:\n",
    "        return batch_count, batch_mean, batch_M2\n",
    "\n",
    "    delta = batch_mean - mean\n",
    "    new_count = count + batch_count\n",
    "    new_mean = mean + delta * batch_count / new_count\n",
    "    new_M2 = M2 + batch_M2 + (delta**2) * count * batch_count / new_count\n",
    "\n",
    "    return new_count, new_mean, new_M2\n",
    "\n",
    "def finalize_vectorized(count, mean, M2):\n",
    "    if count < 2:\n",
    "        raise ValueError(\"At least two samples required.\")\n",
    "    var = M2 / count\n",
    "    std = np.sqrt(var)\n",
    "    return mean, var, std\n",
    "\n",
    "\n",
    "count = 0\n",
    "mean = None\n",
    "M2 = None\n",
    "\n",
    "for batch in data_generator(files, batch_size=64, name=\"x\"):\n",
    "    batch = batch.reshape(-1, 6)\n",
    "    if count == 0:\n",
    "        count, mean, M2 = update_vectorized(0, None, None, batch)\n",
    "    else:\n",
    "        count, mean, M2 = update_vectorized(count, mean, M2, batch)\n",
    "\n",
    "final_mean, final_var, final_std = finalize_vectorized(count, mean, M2)\n",
    "\n",
    "print(\"Mean:\", final_mean)\n",
    "print(\"Std:\", final_std)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05785925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f63c907",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbi_ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
