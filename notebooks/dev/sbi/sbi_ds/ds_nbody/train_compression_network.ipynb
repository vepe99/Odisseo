{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "107c77d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 05:34:43.506751: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746761683.524899 3067450 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746761683.530446 3067450 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746761683.544392 3067450 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746761683.544415 3067450 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746761683.544416 3067450 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746761683.544417 3067450 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "# from autocvd import autocvd\n",
    "# autocvd(num_gpus = 1)\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import jit\n",
    "import optax\n",
    "import haiku as hk\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from tensorflow_probability.substrates import jax as tfp\n",
    "tfb = tfp.bijectors\n",
    "tfd = tfp.distributions\n",
    "\n",
    "\n",
    "from normflow_models import (AffineCoupling,\n",
    "                             AffineSigmoidCoupling,\n",
    "                             ConditionalRealNVP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02a5bb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class to Train the compressor, in our case we are going to train \n",
    "#the compressor with the vmim, so we will also need a Normalizing Flow \n",
    "#  which is going to be trained with the compressor\n",
    "\n",
    "class TrainModel:\n",
    "    def __init__(\n",
    "        self,\n",
    "        compressor,\n",
    "        nf,\n",
    "        optimizer,\n",
    "        loss_name,\n",
    "        dim=None,\n",
    "        info_compressor=None,\n",
    "    ):\n",
    "        self.compressor = compressor\n",
    "        self.nf = nf\n",
    "        self.optimizer = optimizer\n",
    "        self.dim = dim  # summary statistic dimension\n",
    "\n",
    "        if loss_name == \"train_compressor_mse\":\n",
    "            self.loss = self.loss_mse\n",
    "        elif loss_name == \"train_compressor_vmim\":\n",
    "            self.loss = self.loss_vmim\n",
    "        elif loss_name == \"train_compressor_gnll\":\n",
    "            self.loss = self.loss_gnll\n",
    "            if self.dim is None:\n",
    "                raise ValueError(\"dim should be specified when using gnll compressor\")\n",
    "        elif loss_name == \"loss_for_sbi\":\n",
    "            if info_compressor is None:\n",
    "                raise ValueError(\"sbi loss needs compressor informations\")\n",
    "            else:\n",
    "                self.info_compressor = info_compressor\n",
    "                self.loss = self.loss_nll\n",
    "\n",
    "    def loss_mse(self, params, theta, x, state_resnet):\n",
    "        \"\"\"Compute the Mean Squared Error loss\"\"\"\n",
    "        y, opt_state_resnet = self.compressor.apply(params, state_resnet, None, x)\n",
    "\n",
    "        loss = jnp.mean(jnp.sum((y - theta) ** 2, axis=1))\n",
    "\n",
    "        return loss, opt_state_resnet\n",
    "\n",
    "    def loss_mae(self, params, theta, x, state_resnet):\n",
    "        \"\"\"Compute the Mean Absolute Error loss\"\"\"\n",
    "        y, opt_state_resnet = self.compressor.apply(params, state_resnet, None, x)\n",
    "\n",
    "        loss = jnp.mean(jnp.sum(jnp.absolute(y - theta), axis=1))\n",
    "\n",
    "        return loss, opt_state_resnet\n",
    "\n",
    "    def loss_vmim(self, params, theta, x, state_resnet):\n",
    "        \"\"\"Compute the Variational Mutual Information Maximization loss\"\"\"\n",
    "        y, opt_state_resnet = self.compressor.apply(params, state_resnet, None, x)\n",
    "        log_prob = self.nf.apply(params, theta, y)\n",
    "\n",
    "        return -jnp.mean(log_prob), opt_state_resnet\n",
    "\n",
    "    def loss_gnll(self, params, theta, x, state_resnet):\n",
    "        \"\"\"Compute the Gaussian Negative Log Likelihood loss\"\"\"\n",
    "        y, opt_state_resnet = self.compressor.apply(params, state_resnet, None, x)\n",
    "        y_mean = y[..., : self.dim]\n",
    "        y_var = y[..., self.dim :]\n",
    "        y_var = tfb.FillScaleTriL(diag_bijector=tfb.Softplus(low=1e-3)).forward(y_var)\n",
    "\n",
    "        @jax.jit\n",
    "        @jax.vmap\n",
    "        def _get_log_prob(y_mean, y_var, theta):\n",
    "            likelihood = tfd.MultivariateNormalTriL(y_mean, y_var)\n",
    "            return likelihood.log_prob(theta)\n",
    "\n",
    "        loss = -jnp.mean(_get_log_prob(y_mean, y_var, theta))\n",
    "\n",
    "        return loss, opt_state_resnet\n",
    "\n",
    "    def loss_nll(self, params, theta, x, _):\n",
    "        \"\"\"Compute the Negative Log Likelihood loss.\n",
    "        This loss is for inference so it requires to have a trained compressor.\n",
    "        \"\"\"\n",
    "        y, _ = self.compressor.apply(\n",
    "            self.info_compressor[0], self.info_compressor[1], None, x\n",
    "        )\n",
    "        log_prob = self.nf.apply(params, theta, y)\n",
    "\n",
    "        return -jnp.mean(log_prob), _\n",
    "\n",
    "    @partial(jax.jit, static_argnums=(0,))\n",
    "    def update(self, model_params, opt_state, theta, x, state_resnet=None):\n",
    "        (loss, opt_state_resnet), grads = jax.value_and_grad(self.loss, has_aux=True)(\n",
    "            model_params, theta, x, state_resnet\n",
    "        )\n",
    "\n",
    "        updates, new_opt_state = self.optimizer.update(grads, opt_state)\n",
    "\n",
    "        new_params = optax.apply_updates(model_params, updates)\n",
    "\n",
    "        return loss, new_params, new_opt_state, opt_state_resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36dabbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "#mimic the argument parser used in the sbi_bm_lens\n",
    "\n",
    "class args_namedtuple(NamedTuple):\n",
    "\n",
    "    total_steps = 4500,\n",
    "\n",
    "    loss = \"train_compressor_vmim\",\n",
    "    # loss = \"train_compressor_mse\",\n",
    "\n",
    "\n",
    "args = args_namedtuple()\n",
    "dim = 64\n",
    "N_particles = 10_000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17114efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### create compressor \n",
    "\n",
    "#nf \n",
    "bijector_layers_compressor = [128] * 2\n",
    "\n",
    "bijector_compressor = partial(\n",
    "    AffineCoupling, layers=bijector_layers_compressor, activation=jax.nn.silu\n",
    ")\n",
    "\n",
    "NF_compressor = partial(ConditionalRealNVP, n_layers=4, bijector_fn=bijector_compressor)\n",
    "\n",
    "\n",
    "class Flow_nd_Compressor(hk.Module):\n",
    "    def __call__(self, y):\n",
    "        nvp = NF_compressor(dim)(y)\n",
    "        return nvp\n",
    "\n",
    "\n",
    "nf = hk.without_apply_rng(\n",
    "    hk.transform(lambda theta, y: Flow_nd_Compressor()(theta).log_prob(y).squeeze())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03cdfdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.loss == \"train_compressor_gnll\":\n",
    "    compress_dim = int(dim + ((dim**2) - dim) / 2 + dim)\n",
    "else:\n",
    "    compress_dim = dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "045c7918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DeepSetsEncoder(hk.Module):\n",
    "#     def __init__(self, output_dim, hidden_dim: int = 128, name=None):\n",
    "#         super().__init__(name=name)\n",
    "#         self.hidden_dim = hidden_dim\n",
    "#         self.output_dim = output_dim\n",
    "\n",
    "#     def __call__(self, x):  # x: [N_particles, 6]\n",
    "#         # Ï† network: shared across all particles\n",
    "#         mlp_phi = hk.nets.MLP([self.hidden_dim, self.hidden_dim, self.output_dim])\n",
    "#         x_phi = mlp_phi(x)  # shape: [N_particles, output_dim]\n",
    "\n",
    "#         # Pooling over the set dimension (e.g., mean, sum)\n",
    "#         summary = jnp.mean(x_phi, axis=0)  # shape: [output_dim]\n",
    "\n",
    "#         return summary\n",
    "\n",
    "\n",
    "class DeepSetsEncoder(hk.Module):\n",
    "    def __init__(self, output_dim, hidden_dim: int = 128, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def __call__(self, x):  # x: [N_particles, 6] or [B, N_particles, 6]\n",
    "        mlp_phi = hk.nets.MLP([self.hidden_dim, self.hidden_dim, self.hidden_dim, self.output_dim])\n",
    "\n",
    "        if x.ndim == 2:\n",
    "            # Unbatched case: [N_particles, 6]\n",
    "            x_phi = mlp_phi(x)  # [N_particles, output_dim]\n",
    "            summary = jnp.mean(x_phi, axis=0)  # [output_dim]\n",
    "        elif x.ndim == 3:\n",
    "            # Batched case: [B, N_particles, 6]\n",
    "            # Flatten for MLP: [B * N_particles, 6]\n",
    "            B, N, D = x.shape\n",
    "            x_flat = x.reshape(-1, D)\n",
    "            x_phi_flat = mlp_phi(x_flat)  # [B * N_particles, output_dim]\n",
    "            x_phi = x_phi_flat.reshape(B, N, self.output_dim)\n",
    "            summary = jnp.mean(x_phi, axis=1)  # [B, output_dim]\n",
    "        else:\n",
    "            raise ValueError(f\"Input must be of shape (N, D) or (B, N, D), got {x.shape}\")\n",
    "\n",
    "        return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3481ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressor = hk.transform_with_state(\n",
    "    lambda y: DeepSetsEncoder(compress_dim)(y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0ebbc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRAIN\n",
    "# init compressor\n",
    "parameters_SetNet, opt_state_SetNet = compressor.init(\n",
    "    jax.random.PRNGKey(0), y=jnp.ones([1, N_particles, 6])\n",
    ")\n",
    "\n",
    "# init nf\n",
    "params_nf = nf.init(\n",
    "    jax.random.PRNGKey(0), theta=0.5 * jnp.ones([1, 5]), y=0.5 * jnp.ones([1, dim])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f41b87b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = hk.data_structures.merge(parameters_SetNet, params_nf)\n",
    "\n",
    "# x = jnp.ones((1, N_particles, 6))\n",
    "# theta = jnp.ones((1, 5))\n",
    "\n",
    "# y, opt_state_resnet = compressor.apply(params, opt_state_SetNet, None, x)\n",
    "# print(y)\n",
    "# log_prob = nf.apply(params, theta, y)\n",
    "# print(log_prob)\n",
    "\n",
    "# print(-jnp.mean(log_prob), opt_state_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88414f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.loss[0] == \"train_compressor_vmim\":\n",
    "    parameters_compressor = hk.data_structures.merge(parameters_SetNet, params_nf)\n",
    "elif args.loss[0] in [\n",
    "    \"train_compressor_mse\",\n",
    "    \"train_compressor_mae\",\n",
    "    \"train_compressor_gnll\",\n",
    "]:\n",
    "    parameters_compressor = parameters_SetNet\n",
    "\n",
    "\n",
    "# define optimizer\n",
    "total_steps = args.total_steps[0]\n",
    "\n",
    "if args.loss == \"train_compressor_gnll\":\n",
    "    start_lr = 0.0001\n",
    "\n",
    "else:\n",
    "    start_lr = 0.001\n",
    "\n",
    "lr_scheduler = optax.piecewise_constant_schedule(\n",
    "    init_value=start_lr,\n",
    "    boundaries_and_scales={\n",
    "        int(total_steps * 0.1): 0.7,\n",
    "        int(total_steps * 0.2): 0.7,\n",
    "        int(total_steps * 0.3): 0.7,\n",
    "        int(total_steps * 0.4): 0.7,\n",
    "        int(total_steps * 0.5): 0.7,\n",
    "        int(total_steps * 0.6): 0.7,\n",
    "        int(total_steps * 0.7): 0.7,\n",
    "        int(total_steps * 0.8): 0.7,\n",
    "        int(total_steps * 0.9): 0.7,\n",
    "    },\n",
    ")\n",
    "\n",
    "optimizer_c = optax.adam(learning_rate=lr_scheduler)\n",
    "opt_state_c = optimizer_c.init(parameters_compressor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d0e6f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_compressor = TrainModel(\n",
    "    compressor=compressor,\n",
    "    nf=nf,\n",
    "    optimizer=optimizer_c,\n",
    "    loss_name=args.loss[0],\n",
    ")\n",
    "\n",
    "\n",
    "update = jax.jit(model_compressor.update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe9793d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: [5.2568798e+00 5.0465012e+04 1.0516200e+00 9.9948613e+11 1.0474024e+01], std: [2.7393756e+00 2.8652584e+04 5.5082726e-01 2.8847882e+11 5.4957938e+00]\n",
      "mean: [ 1.0705898e-02  1.4870495e-03 -1.9674072e-02  2.4276490e+00\n",
      " -2.1983453e-03  7.1738102e-02], std: [5.95247373e-02 3.69409740e-01 8.38953137e-01 1.04919624e+02\n",
      " 3.17265660e-01 4.72085744e-01]\n",
      "mean: [ 1.2090281e+01 -3.7612926e-06  1.0096312e+00  7.7777201e-10\n",
      " -5.5790531e+01], std: [1.7549825e+03 1.8628102e-03 9.5802881e+03 9.3244665e-08 1.0320980e+04]\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "data_path = '/export/data/vgiusepp/odisseo_data/data/data_NFW/'\n",
    "pattern = re.compile(r\"chunk_(\\d+)\\.npz\")  # capture any number of digits\n",
    "files = sorted(\n",
    "    f for f in Path(data_path).glob(\"chunk_*.npz\")\n",
    "    if (m := pattern.fullmatch(f.name)) and int(m.group(1)) < 70_000\n",
    ")\n",
    "theta_list, x_list, score_list = [], [], []\n",
    "\n",
    "for f in files:\n",
    "    data = np.load(f)\n",
    "    theta_list.append(data[\"theta\"])\n",
    "    x_list.append(data[\"x\"])\n",
    "    score_list.append(data[\"score\"]) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#remove nan values from theta\n",
    "dataset_theta = np.array(theta_list)\n",
    "mask_theta = ~np.isnan(dataset_theta).any(axis=(1))\n",
    "\n",
    "dataset_y = np.array(x_list)\n",
    "mask_y = ~np.isnan(dataset_y).any(axis=(1, 2))\n",
    "\n",
    "dataset_score = np.stack(score_list)\n",
    "mask_score = ~np.isnan(dataset_score).any(axis=(1))\n",
    "\n",
    "#combine the mask \n",
    "total_mask = mask_theta & mask_y & mask_score\n",
    "dataset_theta = dataset_theta[total_mask]\n",
    "dataset_y = dataset_y[total_mask]\n",
    "dataset_score = dataset_score[total_mask]\n",
    "\n",
    "\n",
    "\n",
    "#normalization function\n",
    "# @partial(jax.jit, static_argnums=(1,2))\n",
    "def normalize(dataset, is_observable = False, dataset_name = None):\n",
    "    if is_observable:\n",
    "        # the shape in this case is (N, N_particles, 6)\n",
    "        dataset_original_shape = dataset.shape\n",
    "        normalized_dataset = dataset.reshape(-1, dataset.shape[-1])\n",
    "        mean = np.mean(normalized_dataset, axis=0)\n",
    "        std = np.std(normalized_dataset, axis=0)\n",
    "        normalized_dataset = (normalized_dataset - mean)/ (std + 1e-8) \n",
    "        normalized_dataset = normalized_dataset.reshape(dataset_original_shape)\n",
    "    else:\n",
    "        mean = np.mean(dataset, axis=0)\n",
    "        std = np.std(dataset, axis=0)\n",
    "        normalized_dataset = (dataset - mean)/ (std + 1e-8) \n",
    "\n",
    "    print(f\"mean: {mean}, std: {std}\")\n",
    "    \n",
    "    if dataset_name is not None:\n",
    "        jnp.savez(\n",
    "            f\"./params_compressor/normalization_for_compressor_{dataset_name}.npz\",\n",
    "            mean=mean,\n",
    "            std=std,\n",
    "        )\n",
    "\n",
    "    return normalized_dataset\n",
    "\n",
    "training_set_compress_network = 40_000\n",
    "\n",
    "dataset_theta = normalize(dataset_theta[:training_set_compress_network], dataset_name=\"theta\")\n",
    "dataset_y = normalize(dataset_y[:training_set_compress_network], is_observable=True, dataset_name=\"y\")\n",
    "dataset_score = normalize(dataset_score[:training_set_compress_network], dataset_name=\"score\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709507d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss -159.936:   0%|          | 0/5 [00:33<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "total_steps = 5\n",
    "pbar = tqdm(range(total_steps))\n",
    "store_loss = []\n",
    "len_dataset = len(dataset_theta)\n",
    "index = np.arange(len_dataset)\n",
    "batch_size = 128\n",
    "for i in pbar:\n",
    "    np.random.shuffle(index)\n",
    "    for start_idx in range(0, len_dataset, batch_size):\n",
    "        end_idx = start_idx + batch_size\n",
    "        batch_indices = index[start_idx:end_idx]\n",
    "        batch = batch_indices\n",
    "        # batch = np.random.randint(0, len(dataset_theta), 5) #needs to be checked\n",
    "        theta = jnp.array(dataset_theta[batch])\n",
    "        x = jnp.array(dataset_y[batch])\n",
    "        score = jnp.array(dataset_score[batch])\n",
    "        # print(f\"theta: {theta.shape}, x: {x.shape}, score: {score.shape}\")\n",
    "        if not jnp.isnan(score).any():\n",
    "            b_loss, parameters_compressor, opt_state_c, opt_state_SetNet = update(\n",
    "                model_params=parameters_compressor,\n",
    "                opt_state=opt_state_c,\n",
    "                theta=theta,\n",
    "                x=x,\n",
    "                state_resnet=opt_state_SetNet,\n",
    "            )\n",
    "            store_loss.append(b_loss)\n",
    "            pbar.set_description(f\"loss {b_loss:.3f}\")\n",
    "\n",
    "            if jnp.isnan(b_loss):\n",
    "                print(\"NaN Loss\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bea19ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(store_loss)\n",
    "plt.xlabel(\"Batch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "# plt.yscale('log')\n",
    "# plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f187e57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the compressor \n",
    "\n",
    "compress_data, _ = compressor.apply(\n",
    "    parameters_compressor, opt_state_SetNet, None, dataset_y[:2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540fd50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compress_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50cfe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model \n",
    "import pickle\n",
    "\n",
    "with open(\n",
    "    \"./params_compressor/params_nd_compressor_vmim.pkl\", \"wb\"\n",
    ") as fp:\n",
    "    pickle.dump(parameters_compressor, fp)\n",
    "\n",
    "with open(\"./params_compressor/opt_state_SetNet_vmim.pkl\", \"wb\") as fp:\n",
    "    pickle.dump(opt_state_SetNet, fp)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac1754c",
   "metadata": {},
   "source": [
    "# Batch not loaded in memeory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329648da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_file(file_path):\n",
    "    # Replace with your actual loading logic (e.g., np.load, h5py, etc.)\n",
    "    return np.load(file_path)\n",
    "\n",
    "def data_generator(file_paths, batch_size, name, shuffle=True, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    if shuffle:\n",
    "        rng.shuffle(file_paths)\n",
    "    for i in range(0, len(file_paths), batch_size):\n",
    "        batch_paths = file_paths[i:i+batch_size]\n",
    "        batch = [load_file(p)[name] for p in batch_paths]\n",
    "        yield np.stack(batch)\n",
    "\n",
    "\n",
    "def compute_mean_std(file_paths, batch_size, name):\n",
    "    count = 0\n",
    "    mean = None\n",
    "    M2 = None  # Sum of squares of differences from the current mean\n",
    "\n",
    "    for batch in data_generator(file_paths, batch_size, name, shuffle=False):\n",
    "\n",
    "        if name == \"x\":\n",
    "            print(batch.shape)\n",
    "            batch = batch.reshape(-1, 6)\n",
    "            # x = batch[:, :-1]\n",
    "            x = batch\n",
    "            print(x.shape)\n",
    "        else:\n",
    "            # x = batch[:, :-1]  # assuming last column is target\n",
    "            x = batch\n",
    "\n",
    "        if mean is None:\n",
    "            mean = np.zeros(x.shape[1])\n",
    "            M2 = np.zeros(x.shape[1])\n",
    "    \n",
    "        batch_count = x.shape[0]\n",
    "        batch_mean = np.mean(x, axis=0)\n",
    "        batch_var = np.var(x, axis=0)\n",
    "\n",
    "        delta = batch_mean - mean\n",
    "        total_count = count + batch_count\n",
    "\n",
    "        mean += delta * batch_count / total_count\n",
    "        M2 += batch_var * batch_count + (delta**2) * count * batch_count / total_count\n",
    "\n",
    "        count = total_count\n",
    "    \n",
    "    variance = M2 / count\n",
    "    std = np.sqrt(variance)\n",
    "    return mean, std\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab8017f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10000, 6)\n",
      "(10000000, 6)\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "data_path = './data/data_NFW/'\n",
    "pattern = re.compile(r\"chunk_(\\d+)\\.npz\")  # capture any number of digits\n",
    "files = sorted(\n",
    "    f for f in Path(data_path).glob(\"chunk_*.npz\")\n",
    "    if (m := pattern.fullmatch(f.name)) and int(m.group(1)) < 1_000\n",
    ")\n",
    "\n",
    "mean, std = compute_mean_std(files, batch_size=1000, name=\"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ed2652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.94607902e-02, 7.02848422e-01, 1.75719736e+00, 1.77413414e+02,\n",
       "       4.31594656e-01, 7.39438316e-01])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76ed47f",
   "metadata": {},
   "source": [
    "mean: [ 0.01226011 -0.02244665  0.09708447 -2.625139    0.01436208  0.09414793], std: [9.9460788e-02 7.0284843e-01 1.7571974e+00 1.7741342e+02 4.3159467e-01\n",
    " 7.3943830e-01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfcfc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def update_vectorized(count, mean, M2, batch):\n",
    "    \"\"\"\n",
    "    Vectorized Welford update.\n",
    "    - count: scalar (number of samples seen so far)\n",
    "    - mean: array of shape (D,)\n",
    "    - M2: array of shape (D,)\n",
    "    - batch: shape (B, D)\n",
    "    Returns updated (count, mean, M2)\n",
    "    \"\"\"\n",
    "    batch_count = batch.shape[0]\n",
    "    batch_mean = np.mean(batch, axis=0)\n",
    "    batch_M2 = np.sum((batch - batch_mean) ** 2, axis=0)\n",
    "\n",
    "    if count == 0:\n",
    "        # First batch: initialize\n",
    "        return batch_count, batch_mean, batch_M2\n",
    "\n",
    "    delta = batch_mean - mean\n",
    "    new_count = count + batch_count\n",
    "    new_mean = mean + delta * batch_count / new_count\n",
    "    new_M2 = M2 + batch_M2 + (delta**2) * count * batch_count / new_count\n",
    "\n",
    "    return new_count, new_mean, new_M2\n",
    "\n",
    "def finalize_vectorized(count, mean, M2):\n",
    "    if count < 2:\n",
    "        raise ValueError(\"At least two samples required.\")\n",
    "    var = M2 / count\n",
    "    std = np.sqrt(var)\n",
    "    return mean, var, std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4dc62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume all batches have shape (batch_size, num_features)\n",
    "def compute_mean_std(file_paths, batch_size, name):\n",
    "    initial_count = 0\n",
    "    initial_mean = np.zeros(6)\n",
    "    initial_M2 = np.zeros(6)\n",
    "\n",
    "    aggregate = (initial_count, initial_mean, initial_M2)\n",
    "\n",
    "    for batch in data_generator(file_paths, batch_size, name, shuffle=False):\n",
    "        if name == \"x\":\n",
    "            batch = batch.reshape(-1, 6)\n",
    "        aggregate = update_vectorized(aggregate, batch)\n",
    "\n",
    "    mean, var, sample_var = finalize_vectorized(aggregate)\n",
    "    std = np.sqrt(var)\n",
    "\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3329a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "update_vectorized() missing 2 required positional arguments: 'M2' and 'batch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mcompute_mean_std\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mcompute_mean_std\u001b[39m\u001b[34m(file_paths, batch_size, name)\u001b[39m\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name == \u001b[33m\"\u001b[39m\u001b[33mx\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     11\u001b[39m         batch = batch.reshape(-\u001b[32m1\u001b[39m, \u001b[32m6\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     aggregate = \u001b[43mupdate_vectorized\u001b[49m\u001b[43m(\u001b[49m\u001b[43maggregate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m mean, var, sample_var = finalize_vectorized(aggregate)\n\u001b[32m     15\u001b[39m std = np.sqrt(var)\n",
      "\u001b[31mTypeError\u001b[39m: update_vectorized() missing 2 required positional arguments: 'M2' and 'batch'"
     ]
    }
   ],
   "source": [
    "compute_mean_std(files, batch_size=1000, name=\"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba65fe89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: [ 0.01226027 -0.02244593  0.0970807  -2.62586575  0.0143615   0.09415632]\n",
      "Std: [1.00233859e-01 7.06850254e-01 1.76492770e+00 1.78132901e+02\n",
      " 4.36402014e-01 7.47493294e-01]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ---------- Welfordâ€™s vectorized update ----------\n",
    "def update_vectorized(count, mean, M2, batch):\n",
    "    batch_count = batch.shape[0]\n",
    "    batch_mean = np.mean(batch, axis=0)\n",
    "    batch_M2 = np.sum((batch - batch_mean) ** 2, axis=0)\n",
    "\n",
    "    if count == 0:\n",
    "        return batch_count, batch_mean, batch_M2\n",
    "\n",
    "    delta = batch_mean - mean\n",
    "    new_count = count + batch_count\n",
    "    new_mean = mean + delta * batch_count / new_count\n",
    "    new_M2 = M2 + batch_M2 + (delta**2) * count * batch_count / new_count\n",
    "\n",
    "    return new_count, new_mean, new_M2\n",
    "\n",
    "def finalize_vectorized(count, mean, M2):\n",
    "    if count < 2:\n",
    "        raise ValueError(\"At least two samples required.\")\n",
    "    var = M2 / count\n",
    "    std = np.sqrt(var)\n",
    "    return mean, var, std\n",
    "\n",
    "\n",
    "count = 0\n",
    "mean = None\n",
    "M2 = None\n",
    "\n",
    "for batch in data_generator(files, batch_size=64, name=\"x\"):\n",
    "    batch = batch.reshape(-1, 6)\n",
    "    if count == 0:\n",
    "        count, mean, M2 = update_vectorized(0, None, None, batch)\n",
    "    else:\n",
    "        count, mean, M2 = update_vectorized(count, mean, M2, batch)\n",
    "\n",
    "final_mean, final_var, final_std = finalize_vectorized(count, mean, M2)\n",
    "\n",
    "print(\"Mean:\", final_mean)\n",
    "print(\"Std:\", final_std)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05785925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f63c907",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbi_ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
